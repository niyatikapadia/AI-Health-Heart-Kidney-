{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6481770,"sourceType":"datasetVersion","datasetId":3744886},{"sourceId":13272353,"sourceType":"datasetVersion","datasetId":8411082},{"sourceId":13272588,"sourceType":"datasetVersion","datasetId":8411234},{"sourceId":13272755,"sourceType":"datasetVersion","datasetId":8411339},{"sourceId":13273665,"sourceType":"datasetVersion","datasetId":8411819},{"sourceId":13273699,"sourceType":"datasetVersion","datasetId":8411840},{"sourceId":13273789,"sourceType":"datasetVersion","datasetId":8411883},{"sourceId":13273791,"sourceType":"datasetVersion","datasetId":8411885}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''import pandas as pd\nimport os\nimport numpy as np\n\n# ============================================================\n# 1. Locate the dataset folder\n# ============================================================\nto_combine_path = \"/kaggle/input/nhanes/To Combine\"\n\n# List all CSV files in the folder\ncsv_files = [f for f in os.listdir(to_combine_path) if f.lower().endswith(\".csv\")]\nprint(f\"✅ Found {len(csv_files)} CSV files to combine.\\n\")\n\n# ============================================================\n# 2. Load each CSV safely\n# ============================================================\ndfs = []\nfor file in csv_files:\n    path = os.path.join(to_combine_path, file)\n    try:\n        df = pd.read_csv(path, encoding=\"utf-8\", low_memory=False)\n    except UnicodeDecodeError:\n        df = pd.read_csv(path, encoding=\"latin1\", low_memory=False)\n    dfs.append(df)\n    print(f\"   • Loaded {file:<30} → shape: {df.shape}\")\n\n# ============================================================\n# 3. Identify the key column\n# ============================================================\nkey_candidates = [\"SEQN\", \"Respondent_ID\", \"Participant_ID\"]\nmain_key = None\nfor cand in key_candidates:\n    if any(cand in df.columns for df in dfs):\n        main_key = cand\n        break\nif main_key is None:\n    raise ValueError(\"❌ No common participant ID column found.\")\n\nprint(f\"\\n✅ Using '{main_key}' as merge key.\\n\")\n\n# ============================================================\n# 4. Merge all CSVs\n# ============================================================\nmerged_df = dfs[0]\nfor df in dfs[1:]:\n    merged_df = pd.merge(merged_df, df, on=main_key, how=\"outer\")\n\nprint(f\"✅ Combined dataset shape: {merged_df.shape}\\n\")\n\n# ============================================================\n# 5. Clean up column suffixes (.x/.y duplicates)\n# ============================================================\nmerged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\nmerged_df.columns = merged_df.columns.str.replace(r\"\\.x$|\\.y$\", \"\", regex=True)\n\n# ============================================================\n# 6. Rename important columns (standardize)\n# ============================================================\nrename_map = {\n    \"RIDAGEMN\": \"Age_Months\",\n    \"RIDAGEYR\": \"Age_Years\",\n    \"RIAGENDR\": \"Gender\",\n    \"RIDRETH3\": \"Ethnicity\",\n    \"DMDBORN4\": \"Country_Birth\",\n    \"INDHHIN2\": \"Household_Income\",\n    \"WTINT2YR\": \"Interview_2yr_Weight\",\n    \"SMQ040\": \"Currently_Smoker\",\n    \"ALQ101\": \"Alcohol_Use_Last12mo\",\n    \"PAQ605\": \"Vigorous_Activity\",\n    \"PAQ620\": \"Moderate_Activity\",\n    \"PAD615\": \"Walk_or_Bike\",\n    \"DBQ700\": \"Diet_Quality_Score\",\n    \"DR1TKCAL\": \"Calories_kcal_per_day\",\n    \"DR1TPROT\": \"Protein_g_per_day\",\n    \"DR1TCARB\": \"Carbohydrate_g_per_day\",\n    \"DR1TSUGR\": \"Sugar_g_per_day\",\n    \"DR1TTFAT\": \"Total_Fat_g_per_day\",\n    \"DR1TSODI\": \"Sodium_mg_per_day\",\n    \"BPXSY2\": \"Systolic_BP_Reading2\",\n    \"BPXSY3\": \"Systolic_BP_Reading3\",\n    \"BPXDI2\": \"Diastolic_BP_Reading2\",\n    \"BPXDI3\": \"Diastolic_BP_Reading3\",\n    \"BPQ020\": \"Diagnosed_Hypertension\",\n    \"BMXWT\": \"Weight_kg\",\n    \"BMXHT\": \"Height_cm\",\n    \"BMXARMC\": \"Arm_Circumference_cm\",\n    \"BMXWAIST\": \"Waist_cm\",\n    \"BMXLEG\": \"Leg_Measure_cm\"\n}\nmerged_df.rename(columns=rename_map, inplace=True)\n\n# ============================================================\n# 7. Compute mean systolic & diastolic BP\n# ============================================================\nmerged_df[\"Systolic_BP\"] = merged_df[\n    [\"Systolic_BP_Reading2\", \"Systolic_BP_Reading3\"]\n].mean(axis=1, skipna=True)\n\nmerged_df[\"Diastolic_BP\"] = merged_df[\n    [\"Diastolic_BP_Reading2\", \"Diastolic_BP_Reading3\"]\n].mean(axis=1, skipna=True)\n\n# ============================================================\n# 8. Final column selection (optional)\n# ============================================================\nkeep_cols = [\n    \"Participant_ID\" if \"Participant_ID\" in merged_df.columns else main_key,\n    \"Age_Months\", \"Age_Years\", \"Gender\", \"Ethnicity\",\n    \"Weight_kg\", \"Height_cm\", \"Waist_cm\", \"Arm_Circumference_cm\", \"Leg_Measure_cm\",\n    \"Household_Income\", \"Interview_2yr_Weight\",\n    \"Currently_Smoker\", \"Alcohol_Use_Last12mo\",\n    \"Vigorous_Activity\", \"Moderate_Activity\", \"Walk_or_Bike\",\n    \"Diet_Quality_Score\", \"Calories_kcal_per_day\", \"Protein_g_per_day\",\n    \"Carbohydrate_g_per_day\", \"Sugar_g_per_day\", \"Total_Fat_g_per_day\",\n    \"Sodium_mg_per_day\", \"Diagnosed_Hypertension\",\n    \"Systolic_BP\", \"Diastolic_BP\",\n]\nfinal_cols = [c for c in keep_cols if c in merged_df.columns]\nfinal_df = merged_df[final_cols].copy()\n\n# ============================================================\n# 9. Save cleaned dataset\n# ============================================================\noutput_path = \"/kaggle/working/nhanes_cleaned.csv\"\nfinal_df.to_csv(output_path, index=False)\nprint(f\"\\n✅ Cleaned dataset saved to: {output_path}\")\nprint(f\"✅ Final shape: {final_df.shape}\\n\")\n\n# ============================================================\n# 10. Display column summary\n# ============================================================\nfor i, col in enumerate(final_df.columns[:50], 1):\n    print(f\"{i:03d}. {col}\")\nif len(final_df.columns) > 50:\n    print(f\"... ({len(final_df.columns)} total columns)\")'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.166232Z","iopub.execute_input":"2025-10-20T22:03:38.166471Z","iopub.status.idle":"2025-10-20T22:03:38.178000Z","shell.execute_reply.started":"2025-10-20T22:03:38.166453Z","shell.execute_reply":"2025-10-20T22:03:38.177423Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'import pandas as pd\\nimport os\\nimport numpy as np\\n\\n# ============================================================\\n# 1. Locate the dataset folder\\n# ============================================================\\nto_combine_path = \"/kaggle/input/nhanes/To Combine\"\\n\\n# List all CSV files in the folder\\ncsv_files = [f for f in os.listdir(to_combine_path) if f.lower().endswith(\".csv\")]\\nprint(f\"✅ Found {len(csv_files)} CSV files to combine.\\n\")\\n\\n# ============================================================\\n# 2. Load each CSV safely\\n# ============================================================\\ndfs = []\\nfor file in csv_files:\\n    path = os.path.join(to_combine_path, file)\\n    try:\\n        df = pd.read_csv(path, encoding=\"utf-8\", low_memory=False)\\n    except UnicodeDecodeError:\\n        df = pd.read_csv(path, encoding=\"latin1\", low_memory=False)\\n    dfs.append(df)\\n    print(f\"   • Loaded {file:<30} → shape: {df.shape}\")\\n\\n# ============================================================\\n# 3. Identify the key column\\n# ============================================================\\nkey_candidates = [\"SEQN\", \"Respondent_ID\", \"Participant_ID\"]\\nmain_key = None\\nfor cand in key_candidates:\\n    if any(cand in df.columns for df in dfs):\\n        main_key = cand\\n        break\\nif main_key is None:\\n    raise ValueError(\"❌ No common participant ID column found.\")\\n\\nprint(f\"\\n✅ Using \\'{main_key}\\' as merge key.\\n\")\\n\\n# ============================================================\\n# 4. Merge all CSVs\\n# ============================================================\\nmerged_df = dfs[0]\\nfor df in dfs[1:]:\\n    merged_df = pd.merge(merged_df, df, on=main_key, how=\"outer\")\\n\\nprint(f\"✅ Combined dataset shape: {merged_df.shape}\\n\")\\n\\n# ============================================================\\n# 5. Clean up column suffixes (.x/.y duplicates)\\n# ============================================================\\nmerged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\\nmerged_df.columns = merged_df.columns.str.replace(r\"\\\\.x$|\\\\.y$\", \"\", regex=True)\\n\\n# ============================================================\\n# 6. Rename important columns (standardize)\\n# ============================================================\\nrename_map = {\\n    \"RIDAGEMN\": \"Age_Months\",\\n    \"RIDAGEYR\": \"Age_Years\",\\n    \"RIAGENDR\": \"Gender\",\\n    \"RIDRETH3\": \"Ethnicity\",\\n    \"DMDBORN4\": \"Country_Birth\",\\n    \"INDHHIN2\": \"Household_Income\",\\n    \"WTINT2YR\": \"Interview_2yr_Weight\",\\n    \"SMQ040\": \"Currently_Smoker\",\\n    \"ALQ101\": \"Alcohol_Use_Last12mo\",\\n    \"PAQ605\": \"Vigorous_Activity\",\\n    \"PAQ620\": \"Moderate_Activity\",\\n    \"PAD615\": \"Walk_or_Bike\",\\n    \"DBQ700\": \"Diet_Quality_Score\",\\n    \"DR1TKCAL\": \"Calories_kcal_per_day\",\\n    \"DR1TPROT\": \"Protein_g_per_day\",\\n    \"DR1TCARB\": \"Carbohydrate_g_per_day\",\\n    \"DR1TSUGR\": \"Sugar_g_per_day\",\\n    \"DR1TTFAT\": \"Total_Fat_g_per_day\",\\n    \"DR1TSODI\": \"Sodium_mg_per_day\",\\n    \"BPXSY2\": \"Systolic_BP_Reading2\",\\n    \"BPXSY3\": \"Systolic_BP_Reading3\",\\n    \"BPXDI2\": \"Diastolic_BP_Reading2\",\\n    \"BPXDI3\": \"Diastolic_BP_Reading3\",\\n    \"BPQ020\": \"Diagnosed_Hypertension\",\\n    \"BMXWT\": \"Weight_kg\",\\n    \"BMXHT\": \"Height_cm\",\\n    \"BMXARMC\": \"Arm_Circumference_cm\",\\n    \"BMXWAIST\": \"Waist_cm\",\\n    \"BMXLEG\": \"Leg_Measure_cm\"\\n}\\nmerged_df.rename(columns=rename_map, inplace=True)\\n\\n# ============================================================\\n# 7. Compute mean systolic & diastolic BP\\n# ============================================================\\nmerged_df[\"Systolic_BP\"] = merged_df[\\n    [\"Systolic_BP_Reading2\", \"Systolic_BP_Reading3\"]\\n].mean(axis=1, skipna=True)\\n\\nmerged_df[\"Diastolic_BP\"] = merged_df[\\n    [\"Diastolic_BP_Reading2\", \"Diastolic_BP_Reading3\"]\\n].mean(axis=1, skipna=True)\\n\\n# ============================================================\\n# 8. Final column selection (optional)\\n# ============================================================\\nkeep_cols = [\\n    \"Participant_ID\" if \"Participant_ID\" in merged_df.columns else main_key,\\n    \"Age_Months\", \"Age_Years\", \"Gender\", \"Ethnicity\",\\n    \"Weight_kg\", \"Height_cm\", \"Waist_cm\", \"Arm_Circumference_cm\", \"Leg_Measure_cm\",\\n    \"Household_Income\", \"Interview_2yr_Weight\",\\n    \"Currently_Smoker\", \"Alcohol_Use_Last12mo\",\\n    \"Vigorous_Activity\", \"Moderate_Activity\", \"Walk_or_Bike\",\\n    \"Diet_Quality_Score\", \"Calories_kcal_per_day\", \"Protein_g_per_day\",\\n    \"Carbohydrate_g_per_day\", \"Sugar_g_per_day\", \"Total_Fat_g_per_day\",\\n    \"Sodium_mg_per_day\", \"Diagnosed_Hypertension\",\\n    \"Systolic_BP\", \"Diastolic_BP\",\\n]\\nfinal_cols = [c for c in keep_cols if c in merged_df.columns]\\nfinal_df = merged_df[final_cols].copy()\\n\\n# ============================================================\\n# 9. Save cleaned dataset\\n# ============================================================\\noutput_path = \"/kaggle/working/nhanes_cleaned.csv\"\\nfinal_df.to_csv(output_path, index=False)\\nprint(f\"\\n✅ Cleaned dataset saved to: {output_path}\")\\nprint(f\"✅ Final shape: {final_df.shape}\\n\")\\n\\n# ============================================================\\n# 10. Display column summary\\n# ============================================================\\nfor i, col in enumerate(final_df.columns[:50], 1):\\n    print(f\"{i:03d}. {col}\")\\nif len(final_df.columns) > 50:\\n    print(f\"... ({len(final_df.columns)} total columns)\")'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"'''import pandas as pd\n\n# -----------------------------\n# Load datasets\n# -----------------------------\ndataset1 = pd.read_csv('/kaggle/input/nhanes-cleaned-1/nhanes_cleaned.csv')\ndataset2 = pd.read_excel('/kaggle/input/dataset2/Dataset_Health.xlsx')\n\n# -----------------------------\n# Preprocess dataset2\n# -----------------------------\n# Round Age and convert to int\ndataset2['Age'] = dataset2['Age'].round().astype(int)\n\n# Drop invalid ages (<= 0)\ndataset2 = dataset2[dataset2['Age'] > 0]\n\n# Identify relevant columns\nsteps_cols = [col for col in dataset2.columns if 'Steps' in col]\nhr_cols = [col for col in dataset2.columns if 'HeartRate' in col]\nsleep_cols = [col for col in dataset2.columns if 'SleepDuration' in col]\nnum_cols = steps_cols + hr_cols + sleep_cols + ['Weight', 'Height']\n\n# Convert numeric columns properly\ndataset2[num_cols] = dataset2[num_cols].apply(pd.to_numeric, errors='coerce')\n\n# -----------------------------\n# Aggregate dataset2 by Age\n# -----------------------------\ndataset2_agg = dataset2.groupby('Age').agg(\n    Weight=('Weight', 'mean'),\n    Height=('Height', 'mean')\n).reset_index()\n\n# Calculate averages for 30-day metrics\ndataset2_agg['Steps_Avg'] = dataset2.groupby('Age')[steps_cols].mean().mean(axis=1).values\ndataset2_agg['HeartRate_Avg'] = dataset2.groupby('Age')[hr_cols].mean().mean(axis=1).values\ndataset2_agg['SleepDuration_Avg'] = dataset2.groupby('Age')[sleep_cols].mean().mean(axis=1).values\n\n# -----------------------------\n# Merge with NHANES dataset\n# -----------------------------\nmerged_df = pd.merge(dataset1, dataset2_agg, on='Age', how='outer')\nmerged_df.reset_index(drop=True, inplace=True)\n\n# -----------------------------\n# Remove records with Age < 5\n# -----------------------------\nmerged_df = merged_df[merged_df['Age'] >= 5]\n\n# -----------------------------\n# Identify and display empty columns\n# -----------------------------\nempty_cols = merged_df.columns[merged_df.isna().all()].tolist()\nif empty_cols:\n    print(\"Columns entirely empty (all NaN):\")\n    print(empty_cols)\nelse:\n    print(\"No entirely empty columns found.\")\n\n# -----------------------------\n# Save merged dataset\n# -----------------------------\nmerged_df.to_csv('merged_dataset.csv', index=False)\nprint(\"Merge completed. Dataset saved as 'merged_dataset.csv'.\")\nprint(f\"Final dataset shape: {merged_df.shape}\")'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.179348Z","iopub.execute_input":"2025-10-20T22:03:38.180022Z","iopub.status.idle":"2025-10-20T22:03:38.198682Z","shell.execute_reply.started":"2025-10-20T22:03:38.179994Z","shell.execute_reply":"2025-10-20T22:03:38.198170Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'import pandas as pd\\n\\n# -----------------------------\\n# Load datasets\\n# -----------------------------\\ndataset1 = pd.read_csv(\\'/kaggle/input/nhanes-cleaned-1/nhanes_cleaned.csv\\')\\ndataset2 = pd.read_excel(\\'/kaggle/input/dataset2/Dataset_Health.xlsx\\')\\n\\n# -----------------------------\\n# Preprocess dataset2\\n# -----------------------------\\n# Round Age and convert to int\\ndataset2[\\'Age\\'] = dataset2[\\'Age\\'].round().astype(int)\\n\\n# Drop invalid ages (<= 0)\\ndataset2 = dataset2[dataset2[\\'Age\\'] > 0]\\n\\n# Identify relevant columns\\nsteps_cols = [col for col in dataset2.columns if \\'Steps\\' in col]\\nhr_cols = [col for col in dataset2.columns if \\'HeartRate\\' in col]\\nsleep_cols = [col for col in dataset2.columns if \\'SleepDuration\\' in col]\\nnum_cols = steps_cols + hr_cols + sleep_cols + [\\'Weight\\', \\'Height\\']\\n\\n# Convert numeric columns properly\\ndataset2[num_cols] = dataset2[num_cols].apply(pd.to_numeric, errors=\\'coerce\\')\\n\\n# -----------------------------\\n# Aggregate dataset2 by Age\\n# -----------------------------\\ndataset2_agg = dataset2.groupby(\\'Age\\').agg(\\n    Weight=(\\'Weight\\', \\'mean\\'),\\n    Height=(\\'Height\\', \\'mean\\')\\n).reset_index()\\n\\n# Calculate averages for 30-day metrics\\ndataset2_agg[\\'Steps_Avg\\'] = dataset2.groupby(\\'Age\\')[steps_cols].mean().mean(axis=1).values\\ndataset2_agg[\\'HeartRate_Avg\\'] = dataset2.groupby(\\'Age\\')[hr_cols].mean().mean(axis=1).values\\ndataset2_agg[\\'SleepDuration_Avg\\'] = dataset2.groupby(\\'Age\\')[sleep_cols].mean().mean(axis=1).values\\n\\n# -----------------------------\\n# Merge with NHANES dataset\\n# -----------------------------\\nmerged_df = pd.merge(dataset1, dataset2_agg, on=\\'Age\\', how=\\'outer\\')\\nmerged_df.reset_index(drop=True, inplace=True)\\n\\n# -----------------------------\\n# Remove records with Age < 5\\n# -----------------------------\\nmerged_df = merged_df[merged_df[\\'Age\\'] >= 5]\\n\\n# -----------------------------\\n# Identify and display empty columns\\n# -----------------------------\\nempty_cols = merged_df.columns[merged_df.isna().all()].tolist()\\nif empty_cols:\\n    print(\"Columns entirely empty (all NaN):\")\\n    print(empty_cols)\\nelse:\\n    print(\"No entirely empty columns found.\")\\n\\n# -----------------------------\\n# Save merged dataset\\n# -----------------------------\\nmerged_df.to_csv(\\'merged_dataset.csv\\', index=False)\\nprint(\"Merge completed. Dataset saved as \\'merged_dataset.csv\\'.\")\\nprint(f\"Final dataset shape: {merged_df.shape}\")'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"'''import pandas as pd\n\n# -----------------------------\n# Step 1: Load both datasets\n# -----------------------------\ndataset1 = pd.read_csv('/kaggle/input/merged-nhanes-and-health/merged nhanes and health.csv', low_memory=True)\ndataset2 = pd.read_csv('/kaggle/input/demographic-data/demographic_data.csv', low_memory=True)\n\n# -----------------------------\n# Step 2: Standardize Gender\n# -----------------------------\ngender_map = {'Male': 1, 'M': 1, 'male': 1, 'm': 1,\n              'Female': 2, 'F': 2, 'female': 2, 'f': 2}\ndataset2['Gender'] = dataset2['Gender'].map(gender_map)\n\n# -----------------------------\n# Step 3: Drop unnecessary columns\n# -----------------------------\ncols_to_drop = ['Name', 'Country', 'Income', 'Education Level', 'Credit Score']\ndataset2.drop(columns=[c for c in cols_to_drop if c in dataset2.columns], inplace=True, errors='ignore')\n\n# -----------------------------\n# Step 4: Clean Age\n# -----------------------------\ndataset1['Age'] = pd.to_numeric(dataset1['Age'], errors='coerce').fillna(0).astype(int)\ndataset2['Age'] = pd.to_numeric(dataset2['Age'], errors='coerce').fillna(0).astype(int)\n\n# Drop invalid ages\ndataset1 = dataset1[dataset1['Age'] > 0]\ndataset2 = dataset2[dataset2['Age'] > 0]\n\n# -----------------------------\n# Step 5: Aggregate dataset2 to avoid duplication explosion\n# -----------------------------\ndataset2_agg = dataset2.groupby(['Age', 'Gender']).mean(numeric_only=True).reset_index()\n\n# -----------------------------\n# Step 6: Outer join safely\n# -----------------------------\nmerged_dataset = pd.merge(dataset1, dataset2_agg, on=['Age', 'Gender'], how='outer')\n\n# -----------------------------\n# Step 7: Identify and display empty columns\n# -----------------------------\nempty_columns = merged_dataset.columns[merged_dataset.isna().all()].tolist()\n\nif empty_columns:\n    print(\"\\n⚠️ Columns that are completely empty:\")\n    for col in empty_columns:\n        print(f\"- {col}\")\nelse:\n    print(\"\\n✅ No completely empty columns found.\")\n\n# -----------------------------\n# Step 8: Save the merged dataset\n# -----------------------------\nmerged_dataset.to_csv('combined_dataset.csv', index=False)\nprint(\"\\n✅ Combined dataset saved as 'combined_dataset.csv'\")\nprint(\"Final shape:\", merged_dataset.shape)'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.296153Z","iopub.execute_input":"2025-10-20T22:03:38.296591Z","iopub.status.idle":"2025-10-20T22:03:38.305018Z","shell.execute_reply.started":"2025-10-20T22:03:38.296571Z","shell.execute_reply":"2025-10-20T22:03:38.303996Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'import pandas as pd\\n\\n# -----------------------------\\n# Step 1: Load both datasets\\n# -----------------------------\\ndataset1 = pd.read_csv(\\'/kaggle/input/merged-nhanes-and-health/merged nhanes and health.csv\\', low_memory=True)\\ndataset2 = pd.read_csv(\\'/kaggle/input/demographic-data/demographic_data.csv\\', low_memory=True)\\n\\n# -----------------------------\\n# Step 2: Standardize Gender\\n# -----------------------------\\ngender_map = {\\'Male\\': 1, \\'M\\': 1, \\'male\\': 1, \\'m\\': 1,\\n              \\'Female\\': 2, \\'F\\': 2, \\'female\\': 2, \\'f\\': 2}\\ndataset2[\\'Gender\\'] = dataset2[\\'Gender\\'].map(gender_map)\\n\\n# -----------------------------\\n# Step 3: Drop unnecessary columns\\n# -----------------------------\\ncols_to_drop = [\\'Name\\', \\'Country\\', \\'Income\\', \\'Education Level\\', \\'Credit Score\\']\\ndataset2.drop(columns=[c for c in cols_to_drop if c in dataset2.columns], inplace=True, errors=\\'ignore\\')\\n\\n# -----------------------------\\n# Step 4: Clean Age\\n# -----------------------------\\ndataset1[\\'Age\\'] = pd.to_numeric(dataset1[\\'Age\\'], errors=\\'coerce\\').fillna(0).astype(int)\\ndataset2[\\'Age\\'] = pd.to_numeric(dataset2[\\'Age\\'], errors=\\'coerce\\').fillna(0).astype(int)\\n\\n# Drop invalid ages\\ndataset1 = dataset1[dataset1[\\'Age\\'] > 0]\\ndataset2 = dataset2[dataset2[\\'Age\\'] > 0]\\n\\n# -----------------------------\\n# Step 5: Aggregate dataset2 to avoid duplication explosion\\n# -----------------------------\\ndataset2_agg = dataset2.groupby([\\'Age\\', \\'Gender\\']).mean(numeric_only=True).reset_index()\\n\\n# -----------------------------\\n# Step 6: Outer join safely\\n# -----------------------------\\nmerged_dataset = pd.merge(dataset1, dataset2_agg, on=[\\'Age\\', \\'Gender\\'], how=\\'outer\\')\\n\\n# -----------------------------\\n# Step 7: Identify and display empty columns\\n# -----------------------------\\nempty_columns = merged_dataset.columns[merged_dataset.isna().all()].tolist()\\n\\nif empty_columns:\\n    print(\"\\n⚠️ Columns that are completely empty:\")\\n    for col in empty_columns:\\n        print(f\"- {col}\")\\nelse:\\n    print(\"\\n✅ No completely empty columns found.\")\\n\\n# -----------------------------\\n# Step 8: Save the merged dataset\\n# -----------------------------\\nmerged_dataset.to_csv(\\'combined_dataset.csv\\', index=False)\\nprint(\"\\n✅ Combined dataset saved as \\'combined_dataset.csv\\'\")\\nprint(\"Final shape:\", merged_dataset.shape)'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"'''import pandas as pd\n\n# -----------------------------\n# Step 1: Load both datasets\n# -----------------------------\nd1 = pd.read_csv('/kaggle/input/nhd-dataset/nhd_merged.csv', low_memory=True)\nd2 = pd.read_csv('/kaggle/input/health/health_activity_data.csv', low_memory=True)\n\n# -----------------------------\n# Step 2: Standardize Gender in d2\n# -----------------------------\ngender_map = {'Male': 1, 'M': 1, 'male': 1, 'm': 1,\n              'Female': 2, 'F': 2, 'female': 2, 'f': 2}\nd2['Gender'] = d2['Gender'].map(gender_map)\n\n# -----------------------------\n# Step 3: Clean Age columns\n# -----------------------------\nd1['Age'] = pd.to_numeric(d1['Age'], errors='coerce').fillna(0).astype(int)\nd2['Age'] = pd.to_numeric(d2['Age'], errors='coerce').fillna(0).astype(int)\n\n# Drop invalid ages (e.g., negative or zero)\nd1 = d1[d1['Age'] > 0]\nd2 = d2[d2['Age'] > 0]\n\n# -----------------------------\n# Step 4: Handle duplicate rows in d2 (optional aggregation)\n# -----------------------------\n# If multiple entries exist for same (Age, Gender), average numeric columns\nd2_agg = d2.groupby(['Age', 'Gender']).mean(numeric_only=True).reset_index()\n\n# -----------------------------\n# Step 5: Outer Join\n# -----------------------------\nmerged_df = pd.merge(d1, d2_agg, on=['Age', 'Gender'], how='outer')\n\n# -----------------------------\n# Step 6: Identify completely empty columns\n# -----------------------------\nempty_cols = merged_df.columns[merged_df.isna().all()].tolist()\nif empty_cols:\n    print(\"\\n⚠️ Columns completely empty after merge:\")\n    for col in empty_cols:\n        print(f\"- {col}\")\nelse:\n    print(\"\\n✅ No completely empty columns found.\")\n\n# -----------------------------\n# Step 7: Save Final Merged Dataset\n# -----------------------------\nmerged_df.to_csv('merged_d1_d2.csv', index=False)\nprint(\"\\n✅ Merged dataset saved as 'merged_d1_d2.csv'\")\nprint(\"Final shape:\", merged_df.shape)'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.306383Z","iopub.execute_input":"2025-10-20T22:03:38.306645Z","iopub.status.idle":"2025-10-20T22:03:38.349354Z","shell.execute_reply.started":"2025-10-20T22:03:38.306621Z","shell.execute_reply":"2025-10-20T22:03:38.348597Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'import pandas as pd\\n\\n# -----------------------------\\n# Step 1: Load both datasets\\n# -----------------------------\\nd1 = pd.read_csv(\\'/kaggle/input/nhd-dataset/nhd_merged.csv\\', low_memory=True)\\nd2 = pd.read_csv(\\'/kaggle/input/health/health_activity_data.csv\\', low_memory=True)\\n\\n# -----------------------------\\n# Step 2: Standardize Gender in d2\\n# -----------------------------\\ngender_map = {\\'Male\\': 1, \\'M\\': 1, \\'male\\': 1, \\'m\\': 1,\\n              \\'Female\\': 2, \\'F\\': 2, \\'female\\': 2, \\'f\\': 2}\\nd2[\\'Gender\\'] = d2[\\'Gender\\'].map(gender_map)\\n\\n# -----------------------------\\n# Step 3: Clean Age columns\\n# -----------------------------\\nd1[\\'Age\\'] = pd.to_numeric(d1[\\'Age\\'], errors=\\'coerce\\').fillna(0).astype(int)\\nd2[\\'Age\\'] = pd.to_numeric(d2[\\'Age\\'], errors=\\'coerce\\').fillna(0).astype(int)\\n\\n# Drop invalid ages (e.g., negative or zero)\\nd1 = d1[d1[\\'Age\\'] > 0]\\nd2 = d2[d2[\\'Age\\'] > 0]\\n\\n# -----------------------------\\n# Step 4: Handle duplicate rows in d2 (optional aggregation)\\n# -----------------------------\\n# If multiple entries exist for same (Age, Gender), average numeric columns\\nd2_agg = d2.groupby([\\'Age\\', \\'Gender\\']).mean(numeric_only=True).reset_index()\\n\\n# -----------------------------\\n# Step 5: Outer Join\\n# -----------------------------\\nmerged_df = pd.merge(d1, d2_agg, on=[\\'Age\\', \\'Gender\\'], how=\\'outer\\')\\n\\n# -----------------------------\\n# Step 6: Identify completely empty columns\\n# -----------------------------\\nempty_cols = merged_df.columns[merged_df.isna().all()].tolist()\\nif empty_cols:\\n    print(\"\\n⚠️ Columns completely empty after merge:\")\\n    for col in empty_cols:\\n        print(f\"- {col}\")\\nelse:\\n    print(\"\\n✅ No completely empty columns found.\")\\n\\n# -----------------------------\\n# Step 7: Save Final Merged Dataset\\n# -----------------------------\\nmerged_df.to_csv(\\'merged_d1_d2.csv\\', index=False)\\nprint(\"\\n✅ Merged dataset saved as \\'merged_d1_d2.csv\\'\")\\nprint(\"Final shape:\", merged_df.shape)'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"''''import os\nimport shutil\n\nworking_dir = \"/kaggle/working/\"\n\n# Loop through all files and folders inside the working directory\nfor item in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item)\n    try:\n        if os.path.isfile(item_path) or os.path.islink(item_path):\n            os.remove(item_path)  # delete file or symlink\n        elif os.path.isdir(item_path):\n            shutil.rmtree(item_path)  # delete folder recursively\n        print(f\"✅ Deleted: {item_path}\")\n    except Exception as e:\n        print(f\"⚠️ Could not delete {item_path}: {e}\")\n\nprint(\"\\n✅ All files cleared from /kaggle/working/\")'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.350324Z","iopub.execute_input":"2025-10-20T22:03:38.350595Z","iopub.status.idle":"2025-10-20T22:03:38.367910Z","shell.execute_reply.started":"2025-10-20T22:03:38.350577Z","shell.execute_reply":"2025-10-20T22:03:38.367212Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\'import os\\nimport shutil\\n\\nworking_dir = \"/kaggle/working/\"\\n\\n# Loop through all files and folders inside the working directory\\nfor item in os.listdir(working_dir):\\n    item_path = os.path.join(working_dir, item)\\n    try:\\n        if os.path.isfile(item_path) or os.path.islink(item_path):\\n            os.remove(item_path)  # delete file or symlink\\n        elif os.path.isdir(item_path):\\n            shutil.rmtree(item_path)  # delete folder recursively\\n        print(f\"✅ Deleted: {item_path}\")\\n    except Exception as e:\\n        print(f\"⚠️ Could not delete {item_path}: {e}\")\\n\\nprint(\"\\n✅ All files cleared from /kaggle/working/\")'"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"**FOR NAIL IMAGES**","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y keras tensorflow keras-core\n!pip install tensorflow==2.15.0 keras==2.15.0 tensorflow-addons==0.22.0 --force-reinstall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:03:38.369697Z","iopub.execute_input":"2025-10-20T22:03:38.370153Z","iopub.status.idle":"2025-10-20T22:05:19.636293Z","shell.execute_reply.started":"2025-10-20T22:03:38.370135Z","shell.execute_reply":"2025-10-20T22:05:19.635579Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: keras 3.8.0\nUninstalling keras-3.8.0:\n  Successfully uninstalled keras-3.8.0\nFound existing installation: tensorflow 2.18.0\nUninstalling tensorflow-2.18.0:\n  Successfully uninstalled tensorflow-2.18.0\nFound existing installation: keras-core 0.1.7\nUninstalling keras-core-0.1.7:\n  Successfully uninstalled keras-core-0.1.7\nCollecting tensorflow==2.15.0\n  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting tensorflow-addons==0.22.0\n  Downloading tensorflow_addons-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting absl-py>=1.0.0 (from tensorflow==2.15.0)\n  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\nCollecting astunparse>=1.6.0 (from tensorflow==2.15.0)\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting flatbuffers>=23.5.26 (from tensorflow==2.15.0)\n  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\nCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.0)\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting google-pasta>=0.1.1 (from tensorflow==2.15.0)\n  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\nCollecting h5py>=2.9.0 (from tensorflow==2.15.0)\n  Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting libclang>=13.0.0 (from tensorflow==2.15.0)\n  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\nCollecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==2.15.0)\n  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting packaging (from tensorflow==2.15.0)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting setuptools (from tensorflow==2.15.0)\n  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting six>=1.12.0 (from tensorflow==2.15.0)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting termcolor>=1.1.0 (from tensorflow==2.15.0)\n  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\nCollecting typing-extensions>=3.6.6 (from tensorflow==2.15.0)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n  Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.0)\n  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15.0)\n  Downloading grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.22.0)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nCollecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.15.0)\n  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\nCollecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\nCollecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\nCollecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting cachetools<7.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\nCollecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\nCollecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\nCollecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\nCollecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\nCollecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\nDownloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nDownloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\nDownloading gast-0.6.0-py3-none-any.whl (21 kB)\nDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading grpcio-1.75.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\nDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.3/221.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\nDownloading markdown-3.9-py3-none-any.whl (107 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-6.2.1-py3-none-any.whl (11 kB)\nDownloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\nDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, typeguard, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, gast, charset_normalizer, certifi, cachetools, absl-py, werkzeug, tensorflow-addons, rsa, requests, pyasn1-modules, ml-dtypes, h5py, grpcio, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: libclang\n    Found existing installation: libclang 18.1.1\n    Uninstalling libclang-18.1.1:\n      Successfully uninstalled libclang-18.1.1\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 25.2.10\n    Uninstalling flatbuffers-25.2.10:\n      Successfully uninstalled flatbuffers-25.2.10\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.2\n    Uninstalling wrapt-1.17.2:\n      Successfully uninstalled wrapt-1.17.2\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.45.1\n    Uninstalling wheel-0.45.1:\n      Successfully uninstalled wheel-0.45.1\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.14.0\n    Uninstalling typing_extensions-4.14.0:\n      Successfully uninstalled typing_extensions-4.14.0\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.4\n    Uninstalling typeguard-4.4.4:\n      Successfully uninstalled typeguard-4.4.4\n  Attempting uninstall: termcolor\n    Found existing installation: termcolor 3.1.0\n    Uninstalling termcolor-3.1.0:\n      Successfully uninstalled termcolor-3.1.0\n  Attempting uninstall: tensorflow-io-gcs-filesystem\n    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: six\n    Found existing installation: six 1.17.0\n    Uninstalling six-1.17.0:\n      Successfully uninstalled six-1.17.0\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 75.2.0\n    Uninstalling setuptools-75.2.0:\n      Successfully uninstalled setuptools-75.2.0\n  Attempting uninstall: pyasn1\n    Found existing installation: pyasn1 0.6.1\n    Uninstalling pyasn1-0.6.1:\n      Successfully uninstalled pyasn1-0.6.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: opt-einsum\n    Found existing installation: opt_einsum 3.4.0\n    Uninstalling opt_einsum-3.4.0:\n      Successfully uninstalled opt_einsum-3.4.0\n  Attempting uninstall: oauthlib\n    Found existing installation: oauthlib 3.3.1\n    Uninstalling oauthlib-3.3.1:\n      Successfully uninstalled oauthlib-3.3.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\n  Attempting uninstall: markdown\n    Found existing installation: Markdown 3.8.2\n    Uninstalling Markdown-3.8.2:\n      Successfully uninstalled Markdown-3.8.2\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: gast\n    Found existing installation: gast 0.6.0\n    Uninstalling gast-0.6.0:\n      Successfully uninstalled gast-0.6.0\n  Attempting uninstall: charset_normalizer\n    Found existing installation: charset-normalizer 3.4.2\n    Uninstalling charset-normalizer-3.4.2:\n      Successfully uninstalled charset-normalizer-3.4.2\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2025.6.15\n    Uninstalling certifi-2025.6.15:\n      Successfully uninstalled certifi-2025.6.15\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 5.5.2\n    Uninstalling cachetools-5.5.2:\n      Successfully uninstalled cachetools-5.5.2\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: werkzeug\n    Found existing installation: Werkzeug 3.1.3\n    Uninstalling Werkzeug-3.1.3:\n      Successfully uninstalled Werkzeug-3.1.3\n  Attempting uninstall: rsa\n    Found existing installation: rsa 4.9.1\n    Uninstalling rsa-4.9.1:\n      Successfully uninstalled rsa-4.9.1\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.4\n    Uninstalling requests-2.32.4:\n      Successfully uninstalled requests-2.32.4\n  Attempting uninstall: pyasn1-modules\n    Found existing installation: pyasn1_modules 0.4.2\n    Uninstalling pyasn1_modules-0.4.2:\n      Successfully uninstalled pyasn1_modules-0.4.2\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.14.0\n    Uninstalling h5py-3.14.0:\n      Successfully uninstalled h5py-3.14.0\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.73.1\n    Uninstalling grpcio-1.73.1:\n      Successfully uninstalled grpcio-1.73.1\n  Attempting uninstall: google-pasta\n    Found existing installation: google-pasta 0.2.0\n    Uninstalling google-pasta-0.2.0:\n      Successfully uninstalled google-pasta-0.2.0\n  Attempting uninstall: astunparse\n    Found existing installation: astunparse 1.6.3\n    Uninstalling astunparse-1.6.3:\n      Successfully uninstalled astunparse-1.6.3\n  Attempting uninstall: requests-oauthlib\n    Found existing installation: requests-oauthlib 2.0.0\n    Uninstalling requests-oauthlib-2.0.0:\n      Successfully uninstalled requests-oauthlib-2.0.0\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 2.40.3\n    Uninstalling google-auth-2.40.3:\n      Successfully uninstalled google-auth-2.40.3\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.2\n    Uninstalling google-auth-oauthlib-1.2.2:\n      Successfully uninstalled google-auth-oauthlib-1.2.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.41.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ninflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 cachetools-6.2.1 certifi-2025.10.5 charset_normalizer-3.4.4 flatbuffers-25.9.23 gast-0.6.0 google-auth-2.41.1 google-auth-oauthlib-1.2.2 google-pasta-0.2.0 grpcio-1.75.1 h5py-3.15.1 idna-3.11 keras-2.15.0 libclang-18.1.1 markdown-3.9 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.3.1 opt-einsum-3.4.0 packaging-25.0 protobuf-4.25.8 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.5 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-80.9.0 six-1.17.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-addons-0.22.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 typeguard-2.13.3 typing-extensions-4.15.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\"\"\"# ===============================\n# Imports & Config\n# ===============================\nimport os, time, math, numpy as np, matplotlib.pyplot as plt, seaborn as sns\nimport pandas as pd\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.efficientnet import EfficientNetB1, preprocess_input\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import AdamW\nfrom keras import regularizers, mixed_precision\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\n# ===============================\n# Logging & Seeds\n# ===============================\nmixed_precision.set_global_policy('float32')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nstart_time = time.time()\nprint(\"[INFO] Starting training pipeline...\")\nprint(f\"[INFO] TensorFlow version: {tf.__version__}\")\nimport keras\nprint(f\"[INFO] Keras version: {keras.__version__}\")\n\n# ===============================\n# Paths & Hyperparameters\n# ===============================\ntrain_dir = '/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/train'\ntest_dir = '/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/test'\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nEPOCHS = 15\nFINE_TUNE_EPOCHS = 25\nINIT_LR = 3e-5\nFT_LR = 5e-5\nMIXUP_ALPHA = 0.4\nNUM_FOLDS = 5\n\n# ===============================\n# Data Generators\n# ===============================\ntrain_datagen_base = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n    rotation_range=20,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    zoom_range=0.2,\n    brightness_range=[0.8, 1.2],\n    shear_range=10,\n    horizontal_flip=True,\n    channel_shift_range=20,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\nval_datagen = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n    validation_split=0.2\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\n)\n\ndef mixup_generator(generator, alpha=MIXUP_ALPHA):\n    while True:\n        x, y = next(generator)\n        lam = np.random.beta(alpha, alpha)\n        index = np.random.permutation(len(x))\n        x_mix = lam * x + (1 - lam) * x[index]\n        y_mix = lam * y + (1 - lam) * y[index]\n        yield x_mix, y_mix\n\n# ===============================\n# Model Definition\n# ===============================\ndef build_model(num_classes, dropout_high=0.4):\n    base_model = EfficientNetB1(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n    base_model.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = Dropout(dropout_high)(x)\n    x = Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = Dropout(dropout_high/1.5)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    optimizer = AdamW(learning_rate=INIT_LR, weight_decay=1e-4, clipnorm=1.0)\n    model = Model(inputs=base_model.input, outputs=outputs)\n    model.compile(\n        optimizer=optimizer,\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n        metrics=['accuracy']\n    )\n    return model, base_model\n\n# ===============================\n# Fine-tuning helpers\n# ===============================\ndef unfreeze_last_n_layers(base_model, n):\n    for layer in base_model.layers[-n:]:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n    return base_model\n\ndef progressive_unfreeze(model, base_model, stages, train_gen, val_gen, steps_train, steps_val, class_weights):\n    for n in stages:\n        print(f\"\\n[INFO] Unfreezing last {n} layers for fine-tuning...\")\n        unfreeze_last_n_layers(base_model, n)\n        model.compile(\n            optimizer=AdamW(learning_rate=FT_LR, weight_decay=1e-4, clipnorm=1.0),\n            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n            metrics=['accuracy']\n        )\n        model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=5,\n            steps_per_epoch=steps_train,\n            validation_steps=steps_val,\n            class_weight=class_weights,\n            callbacks=[\n                EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n                LearningRateScheduler(cosine_annealing)\n            ],\n            verbose=1\n        )\n\n# ===============================\n# Cosine LR Scheduler\n# ===============================\ndef cosine_annealing(epoch):\n    max_lr, min_lr, T_max = FT_LR, 1e-6, FINE_TUNE_EPOCHS\n    lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + np.cos(np.pi * epoch / T_max))\n    print(f\"[INFO] Epoch {epoch+1}: learning rate = {lr:.8f}\")\n    return lr\n\n# ===============================\n# Cross Validation Training\n# ===============================\nall_files, all_labels = [], []\nclass_indices = train_datagen_base.flow_from_directory(\n    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n    class_mode='categorical', subset='training', shuffle=False\n).class_indices\nidx_to_class = {v: k for k, v in class_indices.items()}\n\nfor class_name, idx in class_indices.items():\n    class_dir = os.path.join(train_dir, class_name)\n    for f in os.listdir(class_dir):\n        all_files.append(os.path.join(class_dir, f))\n        all_labels.append(idx)\n\nall_files, all_labels = np.array(all_files), np.array(all_labels)\nclass_weights = class_weight.compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\nclass_weights = dict(enumerate(class_weights))\n\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\nfold_histories, fold_val_accuracies = [], []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\n    print(f\"\\n[INFO] Starting fold {fold+1}/{NUM_FOLDS}...\")\n    train_files, val_files = all_files[train_idx], all_files[val_idx]\n    train_labels, val_labels = all_labels[train_idx], all_labels[val_idx]\n\n    # Generators\n    train_generator = ImageDataGenerator(\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n        rotation_range=20, width_shift_range=0.15, height_shift_range=0.15,\n        zoom_range=0.2, brightness_range=[0.8, 1.2],\n        shear_range=10, horizontal_flip=True, channel_shift_range=20, fill_mode='nearest'\n    ).flow_from_dataframe(\n        dataframe=pd.DataFrame({'filename': train_files, 'class': [idx_to_class[label] for label in train_labels]}),\n        x_col='filename', y_col='class', target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True\n    )\n\n    val_generator = ImageDataGenerator(\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\n    ).flow_from_dataframe(\n        dataframe=pd.DataFrame({'filename': val_files, 'class': [idx_to_class[label] for label in val_labels]}),\n        x_col='filename', y_col='class', target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n    )\n\n    train_generator_mixup = mixup_generator(train_generator)\n\n    # Build model\n    model, base_model = build_model(num_classes=len(class_indices))\n\n    # Base training\n    steps_train = math.ceil(len(train_files) / BATCH_SIZE)\n    steps_val = math.ceil(len(val_files) / BATCH_SIZE)\n\n    history = model.fit(\n        train_generator_mixup,\n        validation_data=val_generator,\n        epochs=EPOCHS,\n        steps_per_epoch=steps_train,\n        validation_steps=steps_val,\n        class_weight=class_weights,\n        verbose=1\n    )\n\n    # Progressive fine-tuning\n    progressive_unfreeze(model, base_model, stages=[10, 20, 40],\n                         train_gen=train_generator_mixup,\n                         val_gen=val_generator,\n                         steps_train=steps_train,\n                         steps_val=steps_val,\n                         class_weights=class_weights)\n\n    fold_histories.append(history)\n    val_acc = max(history.history['val_accuracy'])\n    fold_val_accuracies.append(val_acc)\n\n# ===============================\n# Visualization\n# ===============================\nplt.figure(figsize=(12, 5))\nplt.plot(fold_histories[-1].history['accuracy'], label='Train Acc')\nplt.plot(fold_histories[-1].history['val_accuracy'], label='Val Acc')\nplt.title('Training & Validation Accuracy (Last Fold)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# ===============================\n# Confusion Matrix (Last Fold)\n# ===============================\nval_preds = model.predict(val_generator, steps=steps_val, verbose=1)\ny_pred = np.argmax(val_preds, axis=1)\ny_true = val_labels[:len(y_pred)]\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix - Last Fold')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(classification_report(y_true, y_pred))\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:05:19.637206Z","iopub.execute_input":"2025-10-20T22:05:19.637397Z","iopub.status.idle":"2025-10-20T22:05:19.649200Z","shell.execute_reply.started":"2025-10-20T22:05:19.637375Z","shell.execute_reply":"2025-10-20T22:05:19.648364Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'# ===============================\\n# Imports & Config\\n# ===============================\\nimport os, time, math, numpy as np, matplotlib.pyplot as plt, seaborn as sns\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom keras.preprocessing.image import ImageDataGenerator\\nfrom keras.applications.efficientnet import EfficientNetB1, preprocess_input\\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\\nfrom keras.models import Model\\nfrom keras.optimizers import AdamW\\nfrom keras import regularizers, mixed_precision\\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\\nfrom sklearn.utils import class_weight\\nfrom sklearn.metrics import classification_report, confusion_matrix\\nfrom sklearn.model_selection import StratifiedKFold\\n\\n# ===============================\\n# Logging & Seeds\\n# ===============================\\nmixed_precision.set_global_policy(\\'float32\\')\\nos.environ[\\'TF_CPP_MIN_LOG_LEVEL\\'] = \\'2\\'\\nnp.random.seed(42)\\ntf.random.set_seed(42)\\n\\nstart_time = time.time()\\nprint(\"[INFO] Starting training pipeline...\")\\nprint(f\"[INFO] TensorFlow version: {tf.__version__}\")\\nimport keras\\nprint(f\"[INFO] Keras version: {keras.__version__}\")\\n\\n# ===============================\\n# Paths & Hyperparameters\\n# ===============================\\ntrain_dir = \\'/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/train\\'\\ntest_dir = \\'/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/test\\'\\nIMG_SIZE = (224, 224)\\nBATCH_SIZE = 16\\nEPOCHS = 15\\nFINE_TUNE_EPOCHS = 25\\nINIT_LR = 3e-5\\nFT_LR = 5e-5\\nMIXUP_ALPHA = 0.4\\nNUM_FOLDS = 5\\n\\n# ===============================\\n# Data Generators\\n# ===============================\\ntrain_datagen_base = ImageDataGenerator(\\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\\n    rotation_range=20,\\n    width_shift_range=0.15,\\n    height_shift_range=0.15,\\n    zoom_range=0.2,\\n    brightness_range=[0.8, 1.2],\\n    shear_range=10,\\n    horizontal_flip=True,\\n    channel_shift_range=20,\\n    fill_mode=\\'nearest\\',\\n    validation_split=0.2\\n)\\n\\nval_datagen = ImageDataGenerator(\\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\\n    validation_split=0.2\\n)\\n\\ntest_datagen = ImageDataGenerator(\\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\\n)\\n\\ndef mixup_generator(generator, alpha=MIXUP_ALPHA):\\n    while True:\\n        x, y = next(generator)\\n        lam = np.random.beta(alpha, alpha)\\n        index = np.random.permutation(len(x))\\n        x_mix = lam * x + (1 - lam) * x[index]\\n        y_mix = lam * y + (1 - lam) * y[index]\\n        yield x_mix, y_mix\\n\\n# ===============================\\n# Model Definition\\n# ===============================\\ndef build_model(num_classes, dropout_high=0.4):\\n    base_model = EfficientNetB1(include_top=False, weights=\\'imagenet\\', input_shape=(*IMG_SIZE, 3))\\n    base_model.trainable = False\\n    x = GlobalAveragePooling2D()(base_model.output)\\n    x = Dense(512, activation=\\'swish\\', kernel_regularizer=regularizers.l2(1e-4))(x)\\n    x = Dropout(dropout_high)(x)\\n    x = Dense(256, activation=\\'swish\\', kernel_regularizer=regularizers.l2(1e-4))(x)\\n    x = Dropout(dropout_high/1.5)(x)\\n    outputs = Dense(num_classes, activation=\\'softmax\\')(x)\\n\\n    optimizer = AdamW(learning_rate=INIT_LR, weight_decay=1e-4, clipnorm=1.0)\\n    model = Model(inputs=base_model.input, outputs=outputs)\\n    model.compile(\\n        optimizer=optimizer,\\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\\n        metrics=[\\'accuracy\\']\\n    )\\n    return model, base_model\\n\\n# ===============================\\n# Fine-tuning helpers\\n# ===============================\\ndef unfreeze_last_n_layers(base_model, n):\\n    for layer in base_model.layers[-n:]:\\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\\n            layer.trainable = True\\n    return base_model\\n\\ndef progressive_unfreeze(model, base_model, stages, train_gen, val_gen, steps_train, steps_val, class_weights):\\n    for n in stages:\\n        print(f\"\\n[INFO] Unfreezing last {n} layers for fine-tuning...\")\\n        unfreeze_last_n_layers(base_model, n)\\n        model.compile(\\n            optimizer=AdamW(learning_rate=FT_LR, weight_decay=1e-4, clipnorm=1.0),\\n            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\\n            metrics=[\\'accuracy\\']\\n        )\\n        model.fit(\\n            train_gen,\\n            validation_data=val_gen,\\n            epochs=5,\\n            steps_per_epoch=steps_train,\\n            validation_steps=steps_val,\\n            class_weight=class_weights,\\n            callbacks=[\\n                EarlyStopping(monitor=\\'val_loss\\', patience=3, restore_best_weights=True),\\n                LearningRateScheduler(cosine_annealing)\\n            ],\\n            verbose=1\\n        )\\n\\n# ===============================\\n# Cosine LR Scheduler\\n# ===============================\\ndef cosine_annealing(epoch):\\n    max_lr, min_lr, T_max = FT_LR, 1e-6, FINE_TUNE_EPOCHS\\n    lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + np.cos(np.pi * epoch / T_max))\\n    print(f\"[INFO] Epoch {epoch+1}: learning rate = {lr:.8f}\")\\n    return lr\\n\\n# ===============================\\n# Cross Validation Training\\n# ===============================\\nall_files, all_labels = [], []\\nclass_indices = train_datagen_base.flow_from_directory(\\n    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE,\\n    class_mode=\\'categorical\\', subset=\\'training\\', shuffle=False\\n).class_indices\\nidx_to_class = {v: k for k, v in class_indices.items()}\\n\\nfor class_name, idx in class_indices.items():\\n    class_dir = os.path.join(train_dir, class_name)\\n    for f in os.listdir(class_dir):\\n        all_files.append(os.path.join(class_dir, f))\\n        all_labels.append(idx)\\n\\nall_files, all_labels = np.array(all_files), np.array(all_labels)\\nclass_weights = class_weight.compute_class_weight(\\'balanced\\', classes=np.unique(all_labels), y=all_labels)\\nclass_weights = dict(enumerate(class_weights))\\n\\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\\nfold_histories, fold_val_accuracies = [], []\\n\\nfor fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\\n    print(f\"\\n[INFO] Starting fold {fold+1}/{NUM_FOLDS}...\")\\n    train_files, val_files = all_files[train_idx], all_files[val_idx]\\n    train_labels, val_labels = all_labels[train_idx], all_labels[val_idx]\\n\\n    # Generators\\n    train_generator = ImageDataGenerator(\\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\\n        rotation_range=20, width_shift_range=0.15, height_shift_range=0.15,\\n        zoom_range=0.2, brightness_range=[0.8, 1.2],\\n        shear_range=10, horizontal_flip=True, channel_shift_range=20, fill_mode=\\'nearest\\'\\n    ).flow_from_dataframe(\\n        dataframe=pd.DataFrame({\\'filename\\': train_files, \\'class\\': [idx_to_class[label] for label in train_labels]}),\\n        x_col=\\'filename\\', y_col=\\'class\\', target_size=IMG_SIZE,\\n        batch_size=BATCH_SIZE, class_mode=\\'categorical\\', shuffle=True\\n    )\\n\\n    val_generator = ImageDataGenerator(\\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\\n    ).flow_from_dataframe(\\n        dataframe=pd.DataFrame({\\'filename\\': val_files, \\'class\\': [idx_to_class[label] for label in val_labels]}),\\n        x_col=\\'filename\\', y_col=\\'class\\', target_size=IMG_SIZE,\\n        batch_size=BATCH_SIZE, class_mode=\\'categorical\\', shuffle=False\\n    )\\n\\n    train_generator_mixup = mixup_generator(train_generator)\\n\\n    # Build model\\n    model, base_model = build_model(num_classes=len(class_indices))\\n\\n    # Base training\\n    steps_train = math.ceil(len(train_files) / BATCH_SIZE)\\n    steps_val = math.ceil(len(val_files) / BATCH_SIZE)\\n\\n    history = model.fit(\\n        train_generator_mixup,\\n        validation_data=val_generator,\\n        epochs=EPOCHS,\\n        steps_per_epoch=steps_train,\\n        validation_steps=steps_val,\\n        class_weight=class_weights,\\n        verbose=1\\n    )\\n\\n    # Progressive fine-tuning\\n    progressive_unfreeze(model, base_model, stages=[10, 20, 40],\\n                         train_gen=train_generator_mixup,\\n                         val_gen=val_generator,\\n                         steps_train=steps_train,\\n                         steps_val=steps_val,\\n                         class_weights=class_weights)\\n\\n    fold_histories.append(history)\\n    val_acc = max(history.history[\\'val_accuracy\\'])\\n    fold_val_accuracies.append(val_acc)\\n\\n# ===============================\\n# Visualization\\n# ===============================\\nplt.figure(figsize=(12, 5))\\nplt.plot(fold_histories[-1].history[\\'accuracy\\'], label=\\'Train Acc\\')\\nplt.plot(fold_histories[-1].history[\\'val_accuracy\\'], label=\\'Val Acc\\')\\nplt.title(\\'Training & Validation Accuracy (Last Fold)\\')\\nplt.xlabel(\\'Epoch\\')\\nplt.ylabel(\\'Accuracy\\')\\nplt.legend()\\nplt.show()\\n\\n# ===============================\\n# Confusion Matrix (Last Fold)\\n# ===============================\\nval_preds = model.predict(val_generator, steps=steps_val, verbose=1)\\ny_pred = np.argmax(val_preds, axis=1)\\ny_true = val_labels[:len(y_pred)]\\ncm = confusion_matrix(y_true, y_pred)\\nplt.figure(figsize=(8, 6))\\nsns.heatmap(cm, annot=True, fmt=\\'d\\', cmap=\\'Blues\\')\\nplt.title(\\'Confusion Matrix - Last Fold\\')\\nplt.xlabel(\\'Predicted\\')\\nplt.ylabel(\\'Actual\\')\\nplt.show()\\n\\nprint(classification_report(y_true, y_pred))\\n'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# ===============================\n# Imports & Config\n# ===============================\nimport os, time, math, numpy as np, matplotlib.pyplot as plt, seaborn as sns\nimport pandas as pd\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.efficientnet import EfficientNetB1, preprocess_input\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import AdamW\nfrom keras import regularizers, mixed_precision\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\n# ===============================\n# Logging & Seeds\n# ===============================\nmixed_precision.set_global_policy('float32')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nstart_time = time.time()\nprint(\"[INFO] Starting training pipeline...\")\nprint(f\"[INFO] TensorFlow version: {tf.__version__}\")\nimport keras\nprint(f\"[INFO] Keras version: {keras.__version__}\")\n\n# ===============================\n# Paths & Hyperparameters\n# ===============================\ntrain_dir = '/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/train'\ntest_dir = '/kaggle/input/nail-disease-image-classification-dataset/nail_disease_dataset/test'\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nEPOCHS = 15\nFINE_TUNE_EPOCHS = 25\nINIT_LR = 3e-5\nFT_LR = 5e-5\nFT_LR_CLASS2 = 3e-5  # Lower LR for fine-tuning\nMIXUP_ALPHA = 0.4\nNUM_FOLDS = 5\n\n# ===============================\n# Data Generators\n# ===============================\ntrain_datagen_base = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n    rotation_range=20,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    zoom_range=0.2,\n    brightness_range=[0.8, 1.2],\n    shear_range=10,\n    horizontal_flip=True,\n    channel_shift_range=20,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\n# Stronger augmentation for Class 2\ntrain_datagen_class2 = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.3,\n    brightness_range=[0.7, 1.3],\n    shear_range=15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n    validation_split=0.2\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\n)\n\ndef mixup_generator(generator, alpha=MIXUP_ALPHA):\n    while True:\n        x, y = next(generator)\n        lam = np.random.beta(alpha, alpha)\n        index = np.random.permutation(len(x))\n        x_mix = lam * x + (1 - lam) * x[index]\n        y_mix = lam * y + (1 - lam) * y[index]\n        yield x_mix, y_mix\n\n# ===============================\n# Model Definition\n# ===============================\ndef build_model(num_classes, dropout_high=0.4):\n    base_model = EfficientNetB1(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n    base_model.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = Dropout(dropout_high)(x)\n    x = Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n    x = Dropout(dropout_high/1.5)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    optimizer = AdamW(learning_rate=INIT_LR, weight_decay=1e-4, clipnorm=1.0)\n    model = Model(inputs=base_model.input, outputs=outputs)\n    model.compile(\n        optimizer=optimizer,\n        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n        metrics=['accuracy']\n    )\n    return model, base_model\n\n# ===============================\n# Fine-tuning helpers\n# ===============================\ndef unfreeze_last_n_layers(base_model, n):\n    for layer in base_model.layers[-n:]:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n    return base_model\n\ndef progressive_unfreeze(model, base_model, stages, train_gen, val_gen, steps_train, steps_val, class_weights):\n    for n in stages:\n        print(f\"\\n[INFO] Unfreezing last {n} layers for fine-tuning...\")\n        unfreeze_last_n_layers(base_model, n)\n        optimizer = AdamW(learning_rate=FT_LR_CLASS2, weight_decay=1e-4, clipnorm=1.0)\n        model.compile(\n            optimizer=optimizer,\n            loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n            metrics=['accuracy']\n        )\n        model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=5,\n            steps_per_epoch=steps_train,\n            validation_steps=steps_val,\n            class_weight=class_weights,\n            callbacks=[\n                EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n                LearningRateScheduler(cosine_annealing)\n            ],\n            verbose=1\n        )\n\n# ===============================\n# Cosine LR Scheduler\n# ===============================\ndef cosine_annealing(epoch):\n    max_lr, min_lr, T_max = FT_LR_CLASS2, 1e-6, FINE_TUNE_EPOCHS\n    lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + np.cos(np.pi * epoch / T_max))\n    print(f\"[INFO] Epoch {epoch+1}: learning rate = {lr:.8f}\")\n    return lr\n\n# ===============================\n# Cross Validation Training\n# ===============================\nall_files, all_labels = [], []\nclass_indices = train_datagen_base.flow_from_directory(\n    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n    class_mode='categorical', subset='training', shuffle=False\n).class_indices\nidx_to_class = {v: k for k, v in class_indices.items()}\n\nfor class_name, idx in class_indices.items():\n    class_dir = os.path.join(train_dir, class_name)\n    for f in os.listdir(class_dir):\n        all_files.append(os.path.join(class_dir, f))\n        all_labels.append(idx)\n\nall_files, all_labels = np.array(all_files), np.array(all_labels)\nclass_weights = dict(enumerate(class_weight.compute_class_weight(\n    'balanced', classes=np.unique(all_labels), y=all_labels\n)))\n\n# Boost Class 2\nclass_weights[2] *= 1.2\nprint(\"[INFO] Updated class weights:\", class_weights)\n\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\nfold_histories, fold_val_accuracies = [], []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\n    print(f\"\\n[INFO] Starting fold {fold+1}/{NUM_FOLDS}...\")\n    train_files, val_files = all_files[train_idx], all_files[val_idx]\n    train_labels, val_labels = all_labels[train_idx], all_labels[val_idx]\n\n    # Generators\n    train_generator = ImageDataGenerator(\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32)),\n        rotation_range=20, width_shift_range=0.15, height_shift_range=0.15,\n        zoom_range=0.2, brightness_range=[0.8, 1.2],\n        shear_range=10, horizontal_flip=True, channel_shift_range=20, fill_mode='nearest'\n    ).flow_from_dataframe(\n        dataframe=pd.DataFrame({'filename': train_files, 'class': [idx_to_class[label] for label in train_labels]}),\n        x_col='filename', y_col='class', target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True\n    )\n\n    val_generator = ImageDataGenerator(\n        preprocessing_function=lambda x: preprocess_input(x.astype(np.float32))\n    ).flow_from_dataframe(\n        dataframe=pd.DataFrame({'filename': val_files, 'class': [idx_to_class[label] for label in val_labels]}),\n        x_col='filename', y_col='class', target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n    )\n\n    train_generator_mixup = mixup_generator(train_generator)\n\n    # Build model\n    model, base_model = build_model(num_classes=len(class_indices))\n\n    # Base training\n    steps_train = math.ceil(len(train_files) / BATCH_SIZE)\n    steps_val = math.ceil(len(val_files) / BATCH_SIZE)\n\n    history = model.fit(\n        train_generator_mixup,\n        validation_data=val_generator,\n        epochs=EPOCHS,\n        steps_per_epoch=steps_train,\n        validation_steps=steps_val,\n        class_weight=class_weights,\n        verbose=1\n    )\n\n    # Progressive fine-tuning\n    progressive_unfreeze(model, base_model, stages=[10, 20, 40],\n                         train_gen=train_generator_mixup,\n                         val_gen=val_generator,\n                         steps_train=steps_train,\n                         steps_val=steps_val,\n                         class_weights=class_weights)\n\n    fold_histories.append(history)\n    val_acc = max(history.history['val_accuracy'])\n    fold_val_accuracies.append(val_acc)\n\n# ===============================\n# Save final model and weights\n# ===============================\nmodel.save('nail_disease_model.h5')\nmodel.save_weights('nail_disease_model_weights.h5')\nprint(\"[INFO] Saved full model and weights.\")\n\n# ===============================\n# Visualization\n# ===============================\nplt.figure(figsize=(12, 5))\nplt.plot(fold_histories[-1].history['accuracy'], label='Train Acc')\nplt.plot(fold_histories[-1].history['val_accuracy'], label='Val Acc')\nplt.title('Training & Validation Accuracy (Last Fold)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# ===============================\n# Confusion Matrix (Last Fold)\n# ===============================\nval_preds = model.predict(val_generator, steps=steps_val, verbose=1)\ny_pred = np.argmax(val_preds, axis=1)\ny_true = val_labels[:len(y_pred)]\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix - Last Fold')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\nprint(classification_report(y_true, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T22:05:19.650196Z","iopub.execute_input":"2025-10-20T22:05:19.650486Z","iopub.status.idle":"2025-10-21T00:16:17.153961Z","shell.execute_reply.started":"2025-10-20T22:05:19.650464Z","shell.execute_reply":"2025-10-21T00:16:17.153365Z"}},"outputs":[{"name":"stderr","text":"2025-10-20 22:05:21.127707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-10-20 22:05:21.127803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-10-20 22:05:21.129544: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Starting training pipeline...\n[INFO] TensorFlow version: 2.15.0\n[INFO] Keras version: 2.15.0\nFound 933 images belonging to 3 classes.\n[INFO] Updated class weights: {0: 1.5658602150537635, 1: 0.6753623188405797, 2: 1.3625730994152048}\n\n[INFO] Starting fold 1/5...\nFound 931 validated image filenames belonging to 3 classes.\nFound 233 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n27018416/27018416 [==============================] - 1s 0us/step\nEpoch 1/15\n59/59 [==============================] - 62s 895ms/step - loss: 1.2452 - accuracy: 0.4898 - val_loss: 1.0499 - val_accuracy: 0.7167\nEpoch 2/15\n59/59 [==============================] - 49s 831ms/step - loss: 1.0950 - accuracy: 0.6563 - val_loss: 0.9228 - val_accuracy: 0.7768\nEpoch 3/15\n59/59 [==============================] - 49s 828ms/step - loss: 1.0045 - accuracy: 0.7100 - val_loss: 0.8503 - val_accuracy: 0.8069\nEpoch 4/15\n59/59 [==============================] - 48s 817ms/step - loss: 0.9626 - accuracy: 0.7465 - val_loss: 0.8140 - val_accuracy: 0.7940\nEpoch 5/15\n59/59 [==============================] - 49s 841ms/step - loss: 0.9368 - accuracy: 0.7583 - val_loss: 0.7888 - val_accuracy: 0.7768\nEpoch 6/15\n59/59 [==============================] - 47s 794ms/step - loss: 0.9189 - accuracy: 0.7830 - val_loss: 0.7745 - val_accuracy: 0.7854\nEpoch 7/15\n59/59 [==============================] - 46s 783ms/step - loss: 0.8941 - accuracy: 0.7712 - val_loss: 0.7643 - val_accuracy: 0.7768\nEpoch 8/15\n59/59 [==============================] - 46s 782ms/step - loss: 0.8954 - accuracy: 0.7841 - val_loss: 0.7448 - val_accuracy: 0.7983\nEpoch 9/15\n59/59 [==============================] - 46s 783ms/step - loss: 0.8409 - accuracy: 0.8163 - val_loss: 0.7240 - val_accuracy: 0.8026\nEpoch 10/15\n59/59 [==============================] - 46s 781ms/step - loss: 0.8276 - accuracy: 0.8174 - val_loss: 0.7304 - val_accuracy: 0.8069\nEpoch 11/15\n59/59 [==============================] - 48s 822ms/step - loss: 0.8471 - accuracy: 0.7981 - val_loss: 0.7134 - val_accuracy: 0.8197\nEpoch 12/15\n59/59 [==============================] - 45s 772ms/step - loss: 0.8332 - accuracy: 0.8185 - val_loss: 0.7159 - val_accuracy: 0.8155\nEpoch 13/15\n59/59 [==============================] - 45s 767ms/step - loss: 0.8784 - accuracy: 0.8013 - val_loss: 0.6984 - val_accuracy: 0.8283\nEpoch 14/15\n59/59 [==============================] - 48s 809ms/step - loss: 0.8749 - accuracy: 0.8024 - val_loss: 0.7147 - val_accuracy: 0.8112\nEpoch 15/15\n59/59 [==============================] - 46s 777ms/step - loss: 0.8105 - accuracy: 0.8314 - val_loss: 0.7014 - val_accuracy: 0.8283\n\n[INFO] Unfreezing last 10 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 63s 924ms/step - loss: 0.8260 - accuracy: 0.8432 - val_loss: 0.6994 - val_accuracy: 0.8240 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 52s 879ms/step - loss: 0.7720 - accuracy: 0.8539 - val_loss: 0.6960 - val_accuracy: 0.8283 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 48s 820ms/step - loss: 0.8014 - accuracy: 0.8561 - val_loss: 0.6809 - val_accuracy: 0.8240 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 51s 869ms/step - loss: 0.8108 - accuracy: 0.8410 - val_loss: 0.6750 - val_accuracy: 0.8240 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 52s 887ms/step - loss: 0.7814 - accuracy: 0.8561 - val_loss: 0.6775 - val_accuracy: 0.8283 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 20 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 66s 960ms/step - loss: 0.7792 - accuracy: 0.8539 - val_loss: 0.6685 - val_accuracy: 0.8326 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 53s 895ms/step - loss: 0.7912 - accuracy: 0.8571 - val_loss: 0.6635 - val_accuracy: 0.8455 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 51s 866ms/step - loss: 0.7493 - accuracy: 0.8904 - val_loss: 0.6571 - val_accuracy: 0.8627 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 54s 910ms/step - loss: 0.8073 - accuracy: 0.8571 - val_loss: 0.6362 - val_accuracy: 0.8498 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 54s 925ms/step - loss: 0.8176 - accuracy: 0.8389 - val_loss: 0.6521 - val_accuracy: 0.8455 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 40 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 69s 993ms/step - loss: 0.7966 - accuracy: 0.8668 - val_loss: 0.6381 - val_accuracy: 0.8455 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 56s 945ms/step - loss: 0.7451 - accuracy: 0.8904 - val_loss: 0.6382 - val_accuracy: 0.8627 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 58s 980ms/step - loss: 0.7302 - accuracy: 0.9066 - val_loss: 0.6190 - val_accuracy: 0.8712 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 57s 961ms/step - loss: 0.7323 - accuracy: 0.9141 - val_loss: 0.6113 - val_accuracy: 0.8798 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 53s 900ms/step - loss: 0.7400 - accuracy: 0.9098 - val_loss: 0.6068 - val_accuracy: 0.8841 - lr: 2.8206e-05\n\n[INFO] Starting fold 2/5...\nFound 931 validated image filenames belonging to 3 classes.\nFound 233 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n59/59 [==============================] - 58s 850ms/step - loss: 1.1989 - accuracy: 0.4962 - val_loss: 1.0010 - val_accuracy: 0.7339\nEpoch 2/15\n59/59 [==============================] - 47s 794ms/step - loss: 1.0644 - accuracy: 0.6563 - val_loss: 0.9001 - val_accuracy: 0.7940\nEpoch 3/15\n59/59 [==============================] - 50s 845ms/step - loss: 1.0017 - accuracy: 0.7154 - val_loss: 0.8274 - val_accuracy: 0.8412\nEpoch 4/15\n59/59 [==============================] - 47s 794ms/step - loss: 0.9607 - accuracy: 0.7379 - val_loss: 0.7878 - val_accuracy: 0.8369\nEpoch 5/15\n59/59 [==============================] - 47s 794ms/step - loss: 0.9335 - accuracy: 0.7325 - val_loss: 0.7521 - val_accuracy: 0.8584\nEpoch 6/15\n59/59 [==============================] - 46s 782ms/step - loss: 0.8960 - accuracy: 0.7712 - val_loss: 0.7133 - val_accuracy: 0.8884\nEpoch 7/15\n59/59 [==============================] - 48s 816ms/step - loss: 0.9120 - accuracy: 0.7648 - val_loss: 0.7114 - val_accuracy: 0.8627\nEpoch 8/15\n59/59 [==============================] - 45s 764ms/step - loss: 0.8749 - accuracy: 0.8013 - val_loss: 0.6821 - val_accuracy: 0.8970\nEpoch 9/15\n59/59 [==============================] - 46s 787ms/step - loss: 0.8774 - accuracy: 0.7991 - val_loss: 0.6694 - val_accuracy: 0.9013\nEpoch 10/15\n59/59 [==============================] - 45s 768ms/step - loss: 0.9026 - accuracy: 0.7594 - val_loss: 0.6750 - val_accuracy: 0.8841\nEpoch 11/15\n59/59 [==============================] - 46s 790ms/step - loss: 0.8645 - accuracy: 0.8088 - val_loss: 0.6616 - val_accuracy: 0.8884\nEpoch 12/15\n59/59 [==============================] - 46s 774ms/step - loss: 0.8865 - accuracy: 0.7927 - val_loss: 0.6545 - val_accuracy: 0.8927\nEpoch 13/15\n59/59 [==============================] - 47s 791ms/step - loss: 0.8152 - accuracy: 0.8174 - val_loss: 0.6481 - val_accuracy: 0.8970\nEpoch 14/15\n59/59 [==============================] - 48s 822ms/step - loss: 0.8452 - accuracy: 0.8249 - val_loss: 0.6462 - val_accuracy: 0.9013\nEpoch 15/15\n59/59 [==============================] - 47s 803ms/step - loss: 0.8352 - accuracy: 0.8335 - val_loss: 0.6423 - val_accuracy: 0.9013\n\n[INFO] Unfreezing last 10 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 60s 863ms/step - loss: 0.8526 - accuracy: 0.8163 - val_loss: 0.6568 - val_accuracy: 0.8798 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 49s 827ms/step - loss: 0.8669 - accuracy: 0.8077 - val_loss: 0.6556 - val_accuracy: 0.8841 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 47s 801ms/step - loss: 0.8179 - accuracy: 0.8389 - val_loss: 0.6147 - val_accuracy: 0.9185 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 49s 825ms/step - loss: 0.7972 - accuracy: 0.8561 - val_loss: 0.6013 - val_accuracy: 0.9270 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 49s 839ms/step - loss: 0.8399 - accuracy: 0.8421 - val_loss: 0.6221 - val_accuracy: 0.9227 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 20 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 63s 922ms/step - loss: 0.8037 - accuracy: 0.8485 - val_loss: 0.6029 - val_accuracy: 0.9227 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 54s 914ms/step - loss: 0.7869 - accuracy: 0.8496 - val_loss: 0.5837 - val_accuracy: 0.9185 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 50s 849ms/step - loss: 0.7679 - accuracy: 0.8700 - val_loss: 0.5753 - val_accuracy: 0.9313 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 51s 865ms/step - loss: 0.8076 - accuracy: 0.8604 - val_loss: 0.5683 - val_accuracy: 0.9442 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 49s 839ms/step - loss: 0.7589 - accuracy: 0.8980 - val_loss: 0.5693 - val_accuracy: 0.9399 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 40 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 68s 979ms/step - loss: 0.7987 - accuracy: 0.8485 - val_loss: 0.5640 - val_accuracy: 0.9399 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 55s 939ms/step - loss: 0.7740 - accuracy: 0.8754 - val_loss: 0.5630 - val_accuracy: 0.9356 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 54s 912ms/step - loss: 0.8302 - accuracy: 0.8507 - val_loss: 0.5521 - val_accuracy: 0.9356 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 56s 948ms/step - loss: 0.7311 - accuracy: 0.9001 - val_loss: 0.5467 - val_accuracy: 0.9399 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 52s 884ms/step - loss: 0.7381 - accuracy: 0.8937 - val_loss: 0.5358 - val_accuracy: 0.9485 - lr: 2.8206e-05\n\n[INFO] Starting fold 3/5...\nFound 932 validated image filenames belonging to 3 classes.\nFound 232 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n59/59 [==============================] - 57s 829ms/step - loss: 1.2226 - accuracy: 0.4946 - val_loss: 1.0479 - val_accuracy: 0.6422\nEpoch 2/15\n59/59 [==============================] - 46s 787ms/step - loss: 1.0958 - accuracy: 0.6223 - val_loss: 0.9255 - val_accuracy: 0.7845\nEpoch 3/15\n59/59 [==============================] - 45s 771ms/step - loss: 1.0012 - accuracy: 0.7092 - val_loss: 0.8641 - val_accuracy: 0.7931\nEpoch 4/15\n59/59 [==============================] - 45s 769ms/step - loss: 0.9664 - accuracy: 0.7200 - val_loss: 0.8153 - val_accuracy: 0.8060\nEpoch 5/15\n59/59 [==============================] - 48s 809ms/step - loss: 0.9382 - accuracy: 0.7511 - val_loss: 0.7714 - val_accuracy: 0.8448\nEpoch 6/15\n59/59 [==============================] - 46s 781ms/step - loss: 0.9134 - accuracy: 0.7747 - val_loss: 0.7594 - val_accuracy: 0.8147\nEpoch 7/15\n59/59 [==============================] - 45s 768ms/step - loss: 0.9131 - accuracy: 0.7704 - val_loss: 0.7367 - val_accuracy: 0.8405\nEpoch 8/15\n59/59 [==============================] - 49s 831ms/step - loss: 0.9006 - accuracy: 0.7661 - val_loss: 0.7132 - val_accuracy: 0.8491\nEpoch 9/15\n59/59 [==============================] - 47s 804ms/step - loss: 0.8902 - accuracy: 0.8015 - val_loss: 0.7204 - val_accuracy: 0.8448\nEpoch 10/15\n59/59 [==============================] - 48s 812ms/step - loss: 0.8644 - accuracy: 0.8036 - val_loss: 0.7024 - val_accuracy: 0.8621\nEpoch 11/15\n59/59 [==============================] - 48s 813ms/step - loss: 0.8721 - accuracy: 0.7961 - val_loss: 0.6827 - val_accuracy: 0.8664\nEpoch 12/15\n59/59 [==============================] - 49s 834ms/step - loss: 0.8653 - accuracy: 0.8004 - val_loss: 0.6855 - val_accuracy: 0.8621\nEpoch 13/15\n59/59 [==============================] - 48s 819ms/step - loss: 0.8342 - accuracy: 0.8251 - val_loss: 0.6680 - val_accuracy: 0.8707\nEpoch 14/15\n59/59 [==============================] - 49s 842ms/step - loss: 0.8382 - accuracy: 0.8047 - val_loss: 0.6906 - val_accuracy: 0.8319\nEpoch 15/15\n59/59 [==============================] - 47s 800ms/step - loss: 0.8198 - accuracy: 0.8262 - val_loss: 0.6676 - val_accuracy: 0.8621\n\n[INFO] Unfreezing last 10 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 61s 884ms/step - loss: 0.8357 - accuracy: 0.8176 - val_loss: 0.6481 - val_accuracy: 0.8793 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 49s 835ms/step - loss: 0.8180 - accuracy: 0.8487 - val_loss: 0.6300 - val_accuracy: 0.8879 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 50s 855ms/step - loss: 0.8335 - accuracy: 0.8240 - val_loss: 0.6368 - val_accuracy: 0.8836 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 50s 857ms/step - loss: 0.7719 - accuracy: 0.8648 - val_loss: 0.6459 - val_accuracy: 0.8879 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 52s 889ms/step - loss: 0.8020 - accuracy: 0.8594 - val_loss: 0.6237 - val_accuracy: 0.8922 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 20 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 63s 907ms/step - loss: 0.8105 - accuracy: 0.8509 - val_loss: 0.6094 - val_accuracy: 0.9052 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 53s 902ms/step - loss: 0.8148 - accuracy: 0.8509 - val_loss: 0.6167 - val_accuracy: 0.8922 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 49s 835ms/step - loss: 0.8046 - accuracy: 0.8552 - val_loss: 0.5974 - val_accuracy: 0.9052 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 50s 854ms/step - loss: 0.8150 - accuracy: 0.8498 - val_loss: 0.5962 - val_accuracy: 0.8922 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 51s 867ms/step - loss: 0.7895 - accuracy: 0.8702 - val_loss: 0.5971 - val_accuracy: 0.8922 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 40 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 67s 965ms/step - loss: 0.8137 - accuracy: 0.8530 - val_loss: 0.5921 - val_accuracy: 0.8966 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 56s 951ms/step - loss: 0.7940 - accuracy: 0.8691 - val_loss: 0.5709 - val_accuracy: 0.9224 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 54s 909ms/step - loss: 0.7492 - accuracy: 0.8734 - val_loss: 0.6002 - val_accuracy: 0.8836 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 55s 944ms/step - loss: 0.7597 - accuracy: 0.8659 - val_loss: 0.5553 - val_accuracy: 0.9267 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 56s 956ms/step - loss: 0.7009 - accuracy: 0.8916 - val_loss: 0.5603 - val_accuracy: 0.9267 - lr: 2.8206e-05\n\n[INFO] Starting fold 4/5...\nFound 931 validated image filenames belonging to 3 classes.\nFound 233 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n59/59 [==============================] - 59s 867ms/step - loss: 1.2092 - accuracy: 0.4984 - val_loss: 1.0299 - val_accuracy: 0.6567\nEpoch 2/15\n59/59 [==============================] - 49s 838ms/step - loss: 1.0685 - accuracy: 0.6595 - val_loss: 0.9281 - val_accuracy: 0.7296\nEpoch 3/15\n59/59 [==============================] - 47s 806ms/step - loss: 1.0003 - accuracy: 0.7164 - val_loss: 0.8675 - val_accuracy: 0.7511\nEpoch 4/15\n59/59 [==============================] - 48s 812ms/step - loss: 0.9634 - accuracy: 0.7465 - val_loss: 0.8291 - val_accuracy: 0.7425\nEpoch 5/15\n59/59 [==============================] - 48s 809ms/step - loss: 0.9272 - accuracy: 0.7615 - val_loss: 0.7975 - val_accuracy: 0.7682\nEpoch 6/15\n59/59 [==============================] - 48s 807ms/step - loss: 0.9002 - accuracy: 0.7863 - val_loss: 0.7835 - val_accuracy: 0.7639\nEpoch 7/15\n59/59 [==============================] - 45s 770ms/step - loss: 0.8596 - accuracy: 0.8013 - val_loss: 0.7783 - val_accuracy: 0.7597\nEpoch 8/15\n59/59 [==============================] - 46s 784ms/step - loss: 0.8611 - accuracy: 0.8034 - val_loss: 0.7586 - val_accuracy: 0.7597\nEpoch 9/15\n59/59 [==============================] - 47s 793ms/step - loss: 0.8340 - accuracy: 0.8378 - val_loss: 0.7664 - val_accuracy: 0.7725\nEpoch 10/15\n59/59 [==============================] - 46s 775ms/step - loss: 0.8840 - accuracy: 0.8024 - val_loss: 0.7503 - val_accuracy: 0.7811\nEpoch 11/15\n59/59 [==============================] - 45s 769ms/step - loss: 0.8288 - accuracy: 0.8185 - val_loss: 0.7438 - val_accuracy: 0.7811\nEpoch 12/15\n59/59 [==============================] - 48s 815ms/step - loss: 0.8461 - accuracy: 0.8271 - val_loss: 0.7326 - val_accuracy: 0.7940\nEpoch 13/15\n59/59 [==============================] - 48s 815ms/step - loss: 0.8708 - accuracy: 0.8271 - val_loss: 0.7490 - val_accuracy: 0.7768\nEpoch 14/15\n59/59 [==============================] - 48s 817ms/step - loss: 0.8201 - accuracy: 0.8185 - val_loss: 0.7320 - val_accuracy: 0.7811\nEpoch 15/15\n59/59 [==============================] - 50s 849ms/step - loss: 0.8246 - accuracy: 0.8357 - val_loss: 0.7256 - val_accuracy: 0.7854\n\n[INFO] Unfreezing last 10 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 62s 892ms/step - loss: 0.8047 - accuracy: 0.8582 - val_loss: 0.7312 - val_accuracy: 0.7854 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 48s 820ms/step - loss: 0.8494 - accuracy: 0.8324 - val_loss: 0.7205 - val_accuracy: 0.7811 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 48s 813ms/step - loss: 0.7835 - accuracy: 0.8733 - val_loss: 0.7124 - val_accuracy: 0.7940 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 50s 851ms/step - loss: 0.7926 - accuracy: 0.8690 - val_loss: 0.6946 - val_accuracy: 0.8240 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 49s 831ms/step - loss: 0.7696 - accuracy: 0.8733 - val_loss: 0.6840 - val_accuracy: 0.8283 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 20 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 60s 870ms/step - loss: 0.7968 - accuracy: 0.8636 - val_loss: 0.7452 - val_accuracy: 0.7682 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 52s 884ms/step - loss: 0.7608 - accuracy: 0.8904 - val_loss: 0.6780 - val_accuracy: 0.8112 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 50s 849ms/step - loss: 0.7984 - accuracy: 0.8711 - val_loss: 0.6706 - val_accuracy: 0.8283 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 51s 874ms/step - loss: 0.7914 - accuracy: 0.8561 - val_loss: 0.6623 - val_accuracy: 0.8369 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 49s 833ms/step - loss: 0.7696 - accuracy: 0.8926 - val_loss: 0.6590 - val_accuracy: 0.8455 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 40 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 68s 980ms/step - loss: 0.7862 - accuracy: 0.8593 - val_loss: 0.6544 - val_accuracy: 0.8326 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 56s 960ms/step - loss: 0.7403 - accuracy: 0.9044 - val_loss: 0.6632 - val_accuracy: 0.8412 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 54s 912ms/step - loss: 0.7418 - accuracy: 0.8980 - val_loss: 0.6346 - val_accuracy: 0.8541 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 56s 949ms/step - loss: 0.7699 - accuracy: 0.8969 - val_loss: 0.6203 - val_accuracy: 0.8798 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 56s 954ms/step - loss: 0.7237 - accuracy: 0.9087 - val_loss: 0.6292 - val_accuracy: 0.8755 - lr: 2.8206e-05\n\n[INFO] Starting fold 5/5...\nFound 931 validated image filenames belonging to 3 classes.\nFound 233 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n59/59 [==============================] - 60s 889ms/step - loss: 1.2354 - accuracy: 0.5016 - val_loss: 1.0504 - val_accuracy: 0.6996\nEpoch 2/15\n59/59 [==============================] - 46s 778ms/step - loss: 1.1051 - accuracy: 0.6112 - val_loss: 0.9456 - val_accuracy: 0.7210\nEpoch 3/15\n59/59 [==============================] - 43s 735ms/step - loss: 1.0176 - accuracy: 0.6960 - val_loss: 0.8806 - val_accuracy: 0.7339\nEpoch 4/15\n59/59 [==============================] - 49s 837ms/step - loss: 0.9698 - accuracy: 0.7325 - val_loss: 0.8160 - val_accuracy: 0.7597\nEpoch 5/15\n59/59 [==============================] - 49s 828ms/step - loss: 0.9399 - accuracy: 0.7615 - val_loss: 0.8113 - val_accuracy: 0.7382\nEpoch 6/15\n59/59 [==============================] - 49s 838ms/step - loss: 0.9217 - accuracy: 0.7540 - val_loss: 0.7828 - val_accuracy: 0.7597\nEpoch 7/15\n59/59 [==============================] - 47s 793ms/step - loss: 0.9081 - accuracy: 0.7798 - val_loss: 0.7443 - val_accuracy: 0.7854\nEpoch 8/15\n59/59 [==============================] - 48s 816ms/step - loss: 0.8947 - accuracy: 0.8002 - val_loss: 0.7441 - val_accuracy: 0.7811\nEpoch 9/15\n59/59 [==============================] - 48s 818ms/step - loss: 0.8671 - accuracy: 0.7830 - val_loss: 0.7293 - val_accuracy: 0.8069\nEpoch 10/15\n59/59 [==============================] - 47s 789ms/step - loss: 0.8527 - accuracy: 0.8142 - val_loss: 0.7195 - val_accuracy: 0.8069\nEpoch 11/15\n59/59 [==============================] - 45s 770ms/step - loss: 0.8689 - accuracy: 0.8163 - val_loss: 0.7093 - val_accuracy: 0.8069\nEpoch 12/15\n59/59 [==============================] - 48s 810ms/step - loss: 0.8957 - accuracy: 0.7981 - val_loss: 0.7208 - val_accuracy: 0.8069\nEpoch 13/15\n59/59 [==============================] - 47s 792ms/step - loss: 0.8536 - accuracy: 0.7970 - val_loss: 0.6841 - val_accuracy: 0.8326\nEpoch 14/15\n59/59 [==============================] - 47s 803ms/step - loss: 0.8456 - accuracy: 0.8281 - val_loss: 0.6863 - val_accuracy: 0.8240\nEpoch 15/15\n59/59 [==============================] - 47s 791ms/step - loss: 0.8204 - accuracy: 0.8281 - val_loss: 0.6983 - val_accuracy: 0.7983\n\n[INFO] Unfreezing last 10 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 63s 894ms/step - loss: 0.8653 - accuracy: 0.8228 - val_loss: 0.6861 - val_accuracy: 0.8197 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 49s 833ms/step - loss: 0.8410 - accuracy: 0.8260 - val_loss: 0.6611 - val_accuracy: 0.8369 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 50s 852ms/step - loss: 0.7896 - accuracy: 0.8443 - val_loss: 0.6523 - val_accuracy: 0.8412 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 48s 808ms/step - loss: 0.8282 - accuracy: 0.8485 - val_loss: 0.6633 - val_accuracy: 0.8369 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 50s 848ms/step - loss: 0.8109 - accuracy: 0.8528 - val_loss: 0.6509 - val_accuracy: 0.8412 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 20 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 66s 977ms/step - loss: 0.7954 - accuracy: 0.8389 - val_loss: 0.6528 - val_accuracy: 0.8369 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 54s 911ms/step - loss: 0.7525 - accuracy: 0.8776 - val_loss: 0.6157 - val_accuracy: 0.8712 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 54s 912ms/step - loss: 0.8128 - accuracy: 0.8485 - val_loss: 0.6130 - val_accuracy: 0.8755 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 54s 920ms/step - loss: 0.8326 - accuracy: 0.8550 - val_loss: 0.6164 - val_accuracy: 0.8670 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 53s 893ms/step - loss: 0.7753 - accuracy: 0.8593 - val_loss: 0.6120 - val_accuracy: 0.8627 - lr: 2.8206e-05\n\n[INFO] Unfreezing last 40 layers for fine-tuning...\n[INFO] Epoch 1: learning rate = 0.00003000\nEpoch 1/5\n59/59 [==============================] - 68s 977ms/step - loss: 0.8032 - accuracy: 0.8518 - val_loss: 0.6136 - val_accuracy: 0.8712 - lr: 3.0000e-05\n[INFO] Epoch 2: learning rate = 0.00002989\nEpoch 2/5\n59/59 [==============================] - 56s 947ms/step - loss: 0.7645 - accuracy: 0.8969 - val_loss: 0.5996 - val_accuracy: 0.8670 - lr: 2.9886e-05\n[INFO] Epoch 3: learning rate = 0.00002954\nEpoch 3/5\n59/59 [==============================] - 54s 922ms/step - loss: 0.7705 - accuracy: 0.8840 - val_loss: 0.5753 - val_accuracy: 0.9013 - lr: 2.9544e-05\n[INFO] Epoch 4: learning rate = 0.00002898\nEpoch 4/5\n59/59 [==============================] - 54s 920ms/step - loss: 0.7645 - accuracy: 0.8904 - val_loss: 0.5799 - val_accuracy: 0.8970 - lr: 2.8982e-05\n[INFO] Epoch 5: learning rate = 0.00002821\nEpoch 5/5\n59/59 [==============================] - 54s 912ms/step - loss: 0.7252 - accuracy: 0.9055 - val_loss: 0.5764 - val_accuracy: 0.9142 - lr: 2.8206e-05\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Saved full model and weights.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"15/15 [==============================] - 10s 562ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABF4klEQVR4nO3de3zP9f//8ft7a3tvdjSzU2FzPh9CGjnVIkmGko4jnVFMJ32SQ2WlkxynklSUTnQm8cFHLbTQgRxKVGyGZhmG7fX7w8/727vn1Mb77T1et+vn8r5c2uv1er9ej/erffRwfz5fz7fDsixLAAAAwF/4+boAAAAAVDw0iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJwGm0efNmdenSRREREXI4HJo/f75Hz//LL7/I4XDolVde8eh5z2SdOnVSp06dfF3GWc/hcGj06NH/etzo0aPlcDi8XxCAU0aTCNv56aefdPvtt6tmzZoKCgpSeHi42rVrp+eff14HDx706rXT0tL03Xff6fHHH9drr72mVq1aefV6p1P//v3lcDgUHh5e6n3cvHmzHA6HHA6Hnn766XKff8eOHRo9erTWrl3rgWpPj8TERF1xxRWn7XpTp04t118Qjv/7+PsrLi7Oe0UCOGOc4+sCgNPp448/1tVXXy2n06mbbrpJjRs31uHDh7VixQrdd999+uGHH/TCCy945doHDx5UVlaW/vOf/2jw4MFeuUaNGjV08OBBBQQEeOX8/+acc87RgQMH9OGHH6pv375u+2bPnq2goCAdOnTopM69Y8cOjRkzRomJiWrevHmZ3/fZZ5+d1PXORFOnTlV0dLT69+9f5vdceumluummm9y2BQcHe7gyAGcimkTYxtatW9WvXz/VqFFDS5YsUXx8vGvfoEGDtGXLFn388cdeu35eXp4kKTIy0mvXcDgcCgoK8tr5/43T6VS7du30xhtvGE3inDlz1L17d7377runpZYDBw6oUqVKCgwMPC3XO1PVrVtXN9xwg6/LAFABMdwM2xg/frz279+vGTNmuDWIx9WuXVv33HOP6+ejR4/q0UcfVa1ateR0OpWYmKiHHnpIRUVFbu87PqS4YsUKXXDBBQoKClLNmjX16quvuo4ZPXq0atSoIUm677775HA4lJiYKOnYMO3xf/6r0uZuLVq0SBdddJEiIyMVGhqqevXq6aGHHnLtP9GcxCVLlqh9+/YKCQlRZGSkevbsqQ0bNpR6vS1btqh///6KjIxURESEBgwYoAMHDpz4xv7Nddddp08//VT5+fmubatXr9bmzZt13XXXGcfv3btX9957r5o0aaLQ0FCFh4erW7duWrduneuYpUuXqnXr1pKkAQMGuIZFj3/OTp06qXHjxsrOzlaHDh1UqVIl1335+5zEtLQ0BQUFGZ+/a9euqly5snbs2FHmz+oJ//vf/3T11VerevXqcjqdqlatmoYNG2YM2efk5GjAgAE677zz5HQ6FR8fr549e+qXX36RdOz38IcfftCyZctc98cTczF37dqlgQMHKjY2VkFBQWrWrJlmzZpVpveuWLFCrVu3VlBQkGrVqqXp06efcj0ATh+SRNjGhx9+qJo1a6pt27ZlOv6WW27RrFmzdNVVV2n48OFauXKlMjIytGHDBs2bN8/t2C1btuiqq67SwIEDlZaWppdffln9+/dXy5Yt1ahRI/Xu3VuRkZEaNmyYrr32Wl1++eUKDQ0tV/0//PCDrrjiCjVt2lRjx46V0+nUli1b9MUXX/zj+z7//HN169ZNNWvW1OjRo3Xw4EFNmjRJ7dq10zfffGM0qH379lVSUpIyMjL0zTff6KWXXlJMTIyefPLJMtXZu3dv3XHHHXrvvfd08803SzqWItavX1/nn3++cfzPP/+s+fPn6+qrr1ZSUpJyc3M1ffp0dezYUevXr1dCQoIaNGigsWPH6pFHHtFtt92m9u3bS5Lbv8s9e/aoW7du6tevn2644QbFxsaWWt/zzz+vJUuWKC0tTVlZWfL399f06dP12Wef6bXXXlNCQkKZPqenvP322zpw4IDuvPNOValSRatWrdKkSZP022+/6e2333Yd16dPH/3www8aMmSIEhMTtWvXLi1atEjbt29XYmKiJkyYoCFDhig0NFT/+c9/JOmE9+CvDh06pN27d7ttCwsLk9Pp1MGDB9WpUydt2bJFgwcPVlJSkt5++231799f+fn5bn+p+rvvvvtOXbp0UdWqVTV69GgdPXpUo0aNKlNNACoIC7CBffv2WZKsnj17lun4tWvXWpKsW265xW37vffea0mylixZ4tpWo0YNS5K1fPly17Zdu3ZZTqfTGj58uGvb1q1bLUnWU0895XbOtLQ0q0aNGkYNo0aNsv76f9HnnnvOkmTl5eWdsO7j15g5c6ZrW/Pmza2YmBhrz549rm3r1q2z/Pz8rJtuusm43s033+x2zl69ellVqlQ54TX/+jlCQkIsy7Ksq666yrrkkkssy7Ks4uJiKy4uzhozZkyp9+DQoUNWcXGx8TmcTqc1duxY17bVq1cbn+24jh07WpKszMzMUvd17NjRbdvChQstSdZjjz1m/fzzz1ZoaKiVmpr6r5+xvGrUqGF17979H485cOCAsS0jI8NyOBzWtm3bLMuyrD/++KPU352/a9SokfFZ/4mkUl/H7/GECRMsSdbrr7/ues/hw4et5ORkKzQ01CooKHA716hRo1w/p6amWkFBQa7PYFmWtX79esvf39/iPz3AmYHhZthCQUGBpGMJSVl88sknkqT09HS37cOHD5ckY+5iw4YNXemWJFWtWlX16tXTzz//fNI1/93xuYzvv/++SkpKyvSenTt3au3aterfv7+ioqJc25s2bapLL73U9Tn/6o477nD7uX379tqzZ4/rHpbFddddp6VLlyonJ0dLlixRTk5OqUPN0rF5jH5+x/4oKi4u1p49e1xD6d98802Zr+l0OjVgwIAyHdulSxfdfvvtGjt2rHr37q2goCCfDYX+9SGRwsJC7d69W23btpVlWVqzZo3rmMDAQC1dulR//PGHR6/fs2dPLVq0yO3VtWtXScf+fxAXF6drr73WdXxAQIDuvvtu7d+/X8uWLSv1nMXFxVq4cKFSU1NVvXp11/YGDRq4zg2g4qNJhC2Eh4dLkv78888yHb9t2zb5+fmpdu3abtvj4uIUGRmpbdu2uW3/638Ij6tcubJH/4N+zTXXqF27drrlllsUGxurfv366a233vrHhvF4nfXq1TP2NWjQQLt371ZhYaHb9r9/lsqVK0tSuT7L5ZdfrrCwMM2dO1ezZ89W69atjXt5XElJiZ577jnVqVNHTqdT0dHRqlq1qr799lvt27evzNc899xzy/WQytNPP62oqCitXbtWEydOVExMzL++Jy8vTzk5Oa7X/v37y3y9E9m+fburiQ8NDVXVqlXVsWNHSXJ9fqfTqSeffFKffvqpYmNj1aFDB40fP145OTmnfP3zzjtPKSkpbq/jc3a3bdumOnXquJr44xo0aODaX5q8vDwdPHhQderUMfaV9rsIoGKiSYQthIeHKyEhQd9//3253lfWRX/9/f1L3W5Z1klfo7i42O3n4OBgLV++XJ9//rluvPFGffvtt7rmmmt06aWXGseeilP5LMc5nU717t1bs2bN0rx5806YIkrSuHHjlJ6erg4dOuj111/XwoULtWjRIjVq1KjMialU/mVb1qxZo127dkk6Nn+uLFq3bq34+HjX62TWe/yr4uJiXXrppfr444/1wAMPaP78+Vq0aJHrgZy/fv6hQ4dq06ZNysjIUFBQkEaOHKkGDRq40kYA8DQeXIFtXHHFFXrhhReUlZWl5OTkfzy2Ro0aKikp0ebNm12piSTl5uYqPz/f9aSyJ1SuXNntSeDjSktp/Pz8dMkll+iSSy7Rs88+q3Hjxuk///mP/vvf/yolJaXUzyFJGzduNPb9+OOPio6OVkhIyKl/iFJcd911evnll+Xn56d+/fqd8Lh33nlHnTt31owZM9y25+fnKzo62vWzJ7+lo7CwUAMGDFDDhg3Vtm1bjR8/Xr169XI9QX0is2fPdnvquGbNmqdUx3fffadNmzZp1qxZbmsVLlq0qNTja9WqpeHDh2v48OHavHmzmjdvrmeeeUavv/66JM/eI+nY78+3336rkpIStzTxxx9/dO0vTdWqVRUcHKzNmzcb+0r7XQRQMZEkwjbuv/9+hYSE6JZbblFubq6x/6efftLzzz8v6dhwqSRNmDDB7Zhnn31WktS9e3eP1VWrVi3t27dP3377rWvbzp07jSeo9+7da7z3+KLSf1+W57j4+Hg1b95cs2bNcmtEv//+e3322Weuz+kNnTt31qOPPqrJkyf/4zd4+Pv7Gynl22+/rd9//91t2/FmtrSGurweeOABbd++XbNmzdKzzz6rxMREpaWlnfA+HteuXTu3YdlTbRKPp7Z//fyWZbl+D487cOCAsQh5rVq1FBYW5lZzSEiIR+7PcZdffrlycnI0d+5c17ajR49q0qRJCg0NdQ2L/52/v7+6du2q+fPna/v27a7tGzZs0MKFCz1WHwDvIkmEbdSqVUtz5szRNddcowYNGrh948qXX37pWtpDkpo1a6a0tDS98MILys/PV8eOHbVq1SrNmjVLqamp6ty5s8fq6tevnx544AH16tVLd999tw4cOKBp06apbt26bg9ujB07VsuXL1f37t1Vo0YN7dq1S1OnTtV5552niy666ITnf+qpp9StWzclJydr4MCBriVwIiIiyvRduyfLz89PDz/88L8ed8UVV2js2LEaMGCA2rZtq++++06zZ882GrBatWopMjJSmZmZCgsLU0hIiNq0aaOkpKRy1bVkyRJNnTpVo0aNci3JM3PmTHXq1EkjR47U+PHjy3W+f7NlyxY99thjxvYWLVqoS5cuqlWrlu699179/vvvCg8P17vvvmvM/9y0aZMuueQS9e3bVw0bNtQ555yjefPmKTc31y2lbdmypaZNm6bHHntMtWvXVkxMjC6++OKTrv22227T9OnT1b9/f2VnZysxMVHvvPOOvvjiC02YMOEfHwQbM2aMFixYoPbt2+uuu+5yNZeNGjVy+wsRgArMl49WA76wadMm69Zbb7USExOtwMBAKywszGrXrp01adIk69ChQ67jjhw5Yo0ZM8ZKSkqyAgICrGrVqlkjRoxwO8ayTrzMyd+XXjnREjiWZVmfffaZ1bhxYyswMNCqV6+e9frrrxtL4CxevNjq2bOnlZCQYAUGBloJCQnWtddea23atMm4xt+Xifn888+tdu3aWcHBwVZ4eLjVo0cPa/369W7HHL/e35fYmTlzpiXJ2rp16wnvqWW5L4FzIidaAmf48OFWfHy8FRwcbLVr187Kysoqdema999/32rYsKF1zjnnuH3Ojh07Wo0aNSr1mn89T0FBgVWjRg3r/PPPt44cOeJ23LBhwyw/Pz8rKyvrHz9DeRxfHqm018CBAy3LOrYsTEpKihUaGmpFR0dbt956q7Vu3Tq3z7d7925r0KBBVv369a2QkBArIiLCatOmjfXWW2+5XS8nJ8fq3r27FRYWZkn61+VwJFmDBg36x2Nyc3OtAQMGWNHR0VZgYKDVpEmTUpch0t+WwLEsy1q2bJnVsmVLKzAw0KpZs6aVmZlp/F4DqLgcllWO2egAAACwBeYkAgAAwECTCAAAAANNIgAAAAw0iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMZ+U3rtz/Md8NiopnbNd6vi4BcFPCMrmoYCoFePb7x8sjuMVgr5374JrJ5Tp++fLleuqpp5Sdne36mtbU1FTXfsuyNGrUKL344ovKz89Xu3btNG3aNNWpU8d1zN69ezVkyBB9+OGH8vPzU58+ffT8888rNDS0zHWQJAIAAFQghYWFatasmaZMmVLq/vHjx2vixInKzMzUypUrFRISoq5du7p9x/v111+vH374QYsWLdJHH32k5cuX67bbbitXHWdlkggAAFAujoqTm3Xr1k3dunUrdZ9lWZowYYIefvhh9ezZU5L06quvKjY2VvPnz1e/fv20YcMGLViwQKtXr1arVq0kSZMmTdLll1+up59+WgkJCWWqo+LcEQAAAF9xOLz2KioqUkFBgdurqKjopMrcunWrcnJylJKS4toWERGhNm3aKCsrS5KUlZWlyMhIV4MoSSkpKfLz89PKlSvLfC2aRAAAAC/KyMhQRESE2ysjI+OkzpWTkyNJio2NddseGxvr2peTk6OYmBi3/eecc46ioqJcx5QFw80AAABeHG4eMWKE0tPT3bY5nU6vXc9TaBIBAAC8yOl0eqwpjIuLkyTl5uYqPj7etT03N1fNmzd3HbNr1y639x09elR79+51vb8sGG4GAADw4pxET0pKSlJcXJwWL17s2lZQUKCVK1cqOTlZkpScnKz8/HxlZ2e7jlmyZIlKSkrUpk2bMl+LJBEAAKAC2b9/v7Zs2eL6eevWrVq7dq2ioqJUvXp1DR06VI899pjq1KmjpKQkjRw5UgkJCa61FBs0aKDLLrtMt956qzIzM3XkyBENHjxY/fr1K/OTzRJNIgAAQIVaAufrr79W586dXT8fn8+YlpamV155Rffff78KCwt12223KT8/XxdddJEWLFigoKAg13tmz56twYMH65JLLnEtpj1x4sRy1eGwrLNvyX2+cQUVEd+4goqGb1xBRePTb1y54F6vnfvgqqe9dm5vIkkEAADw8NzBswFNIgAAQAUabq4ouCMAAAAwkCQCAAAw3GwgSQQAAICBJBEAAIA5iQbuCAAAAAwkiQAAAMxJNJAkAgAAwECSCAAAwJxEA00iAAAAw80G2mYAAAAYSBIBAAAYbjZwRwAAAGAgSQQAACBJNHBHAAAAYCBJBAAA8OPp5r8jSQQAAICBJBEAAIA5iQaaRAAAABbTNtA2AwAAwECSCAAAwHCzgTsCAAAAA0kiAAAAcxINJIkAAAAwkCQCAAAwJ9HAHQEAAICBJBEAAIA5iQaaRAAAAIabDdwRAAAAGEgSAQAAGG42kCQCAADAQJIIAADAnEQDdwQAAAAGkkQAAADmJBpIEgEAAGAgSQQAAGBOooEmEQAAgCbRwB0BAACAgSQRAACAB1cMJIkAAAAwkCQCAAAwJ9HAHQEAAICBJBEAAIA5iQaSRAAAABhIEgEAAJiTaKBJBAAAYLjZQNsMAAAAA0kiAACwPQdJooEkEQAAAAaSRAAAYHskiSaSRAAAABhIEgEAAAgSDSSJAAAAMJAkAgAA22NOookmEQAA2B5NoonhZgAAABhIEgEAgO2RJJpIEgEAAGAgSQQAALZHkmiiSYSbTYvf0YaPX1XN9j3UpNetkqRDBX/ohw9nKm/TWh0tOqjQqueqbkpfJTRr6+NqYTdvzpmtWTNnaPfuPNWtV18PPjRSTZo29XVZsKnsr1fr1ZkztH79D9qdl6dnn5+szpek+LoswGMYbobLH9s3a1vWAoXHJ7pt/2bOc9q/63e1uflhdb5vkuKbJmv1q+OV/9tPvikUtrTg00/09PgM3X7XIL359jzVq1dfd94+UHv27PF1abCpgwcPqm69+hrxn0d8XQo8weHF1xmKJhGSpKNFB5U9+xk16ztYAZVC3fbt/eVH1Wx/hSrXqKuQKnGqd+k1CggO0T6aRJxGr82aqd5X9VVqrz6qVbu2Hh41RkFBQZr/3ru+Lg02dVH7Dhp091BdnHKpr0sBvIImEZKkb9/NVGyDVoqp29zYF5VYX7+v/Z8OF/4pq6REv61ZrpKjh1WlVuPTXyhs6cjhw9qw/gddmPx/Uxz8/Px04YVt9e26NT6sDMDZwuFweO11pvLpnMTdu3fr5ZdfVlZWlnJyciRJcXFxatu2rfr376+qVav6sjzb+G3NcuX/9rM6Dnum1P2t0+7X6lef0qcjr5fDz1/+gU5dMOAhhVZNOM2Vwq7+yP9DxcXFqlKlitv2KlWqaOvWn31UFQCc3XzWJK5evVpdu3ZVpUqVlJKSorp160qScnNzNXHiRD3xxBNauHChWrVq9Y/nKSoqUlFRkdu2o0cO65yAQK/VfjY5+Eeevp/3opLvGCv/E9yzDZ/O1pGDhWp7x6MKDAnXzu+/0upZ49V+cIbCExJPb8EAAHjBmZz4eYvPmsQhQ4bo6quvVmZmpvEvxrIs3XHHHRoyZIiysrL+8TwZGRkaM2aM27a21w5Su+uHeLzms1H+bz+paP8+LXt2mGubVVKiPT//oK1ffKxLHpymrSs+Vuf7Jys8rrokKeLcJO35eb22fvGJml19l69Kh41Ujqwsf39/4yGVPXv2KDo62kdVATib0CSafNYkrlu3Tq+88kqp/1IcDoeGDRumFi1a/Ot5RowYofT0dLdto5ds81idZ7voOk3V+b5JbtvWvPm8QmPOU52L+6j48LGU9u//nhx+frKsktNWJ+wtIDBQDRo20sqvsnTx/19ipKSkRCtXZqnftTf4uDoAODv5rEmMi4vTqlWrVL9+/VL3r1q1SrGxsf96HqfTKafT6baNoeayCwiqpID4Gm7b/AODFFgpTOHxNVRSfFQh0fFa9/YUNepxswJDwrTz+6+Ut2mtLhw40kdVw45uTBugkQ89oEaNGqtxk6Z6/bVZOnjwoFJ79fZ1abCpAwcK9ev27a6ff//9N238cYPCIyIUH8+c7TMNSaLJZ03ivffeq9tuu03Z2dm65JJLXA1hbm6uFi9erBdffFFPP/20r8rD/+fnf44uvHWU1n80SytnPKqjhw8ppEq8zr92qGIb/vN8UcCTLut2uf7Yu1dTJ0/U7t15qle/gaZOf0lVGG6Gj6z//nvdenOa6+dnxj8hSerRM1VjH3/CV2UBHuOwLMvy1cXnzp2r5557TtnZ2SouLpYk+fv7q2XLlkpPT1ffvn1P6rz3f7zRk2UCHjG2az1flwC4KfHdH/9AqSoF+C7Nq5L2htfOvWfWtV47tzf5dAmca665Rtdcc42OHDmi3bt3S5Kio6MVEBDgy7IAAABsr0J8d3NAQIDi4+N9XQYAALAp5iSa+MYVAAAAGCpEkggAAOBLJIkmmkQAAGB7NIkmhpsBAABgIEkEAAAgSDSQJAIAAMBAkggAAGyPOYkmkkQAAAAYaBIBAIDtORwOr73Ko7i4WCNHjlRSUpKCg4NVq1YtPfroo/rrtyhblqVHHnlE8fHxCg4OVkpKijZv3uzpW0KTCAAAUFE8+eSTmjZtmiZPnqwNGzboySef1Pjx4zVp0iTXMePHj9fEiROVmZmplStXKiQkRF27dtWhQ4c8WgtzEgEAgO1VlDmJX375pXr27Knu3btLkhITE/XGG29o1apVko6liBMmTNDDDz+snj17SpJeffVVxcbGav78+erXr5/HaiFJBAAAtufN4eaioiIVFBS4vYqKikqto23btlq8eLE2bdokSVq3bp1WrFihbt26SZK2bt2qnJwcpaSkuN4TERGhNm3aKCsry6P3hCYRAADAizIyMhQREeH2ysjIKPXYBx98UP369VP9+vUVEBCgFi1aaOjQobr++uslSTk5OZKk2NhYt/fFxsa69nkKw80AAABeHG0eMWKE0tPT3bY5nc5Sj33rrbc0e/ZszZkzR40aNdLatWs1dOhQJSQkKC0tzXtFloImEQAAwIucTucJm8K/u++++1xpoiQ1adJE27ZtU0ZGhtLS0hQXFydJys3NVXx8vOt9ubm5at68uUfrZrgZAADYXkVZAufAgQPy83Nvz/z9/VVSUiJJSkpKUlxcnBYvXuzaX1BQoJUrVyo5OfnUb8RfkCQCAABUED169NDjjz+u6tWrq1GjRlqzZo2effZZ3XzzzZKONbNDhw7VY489pjp16igpKUkjR45UQkKCUlNTPVoLTSIAALC9irIEzqRJkzRy5Ejddddd2rVrlxISEnT77bfrkUcecR1z//33q7CwULfddpvy8/N10UUXacGCBQoKCvJoLQ7rr0t4nyXu/3ijr0sADGO71vN1CYCbkrPvj3+c4SoF+K5RO++u+V47929TU712bm8iSQQAALZXUZLEioQmEQAAgB7RwNPNAAAAMJAkAgAA22O42USSCAAAAANJIgAAsD2SRBNJIgAAAAwkiQAAwPZIEk0kiQAAADCQJAIAANsjSTTRJAIAANAjGhhuBgAAgIEkEQAA2B7DzSaSRAAAABhIEgEAgO2RJJpIEgEAAGAgSQQAALZHkGgiSQQAAICBJBEAANgecxJNNIkAAMD26BFNDDcDAADAQJIIAABsj+FmE0kiAAAADCSJAADA9ggSTSSJAAAAMJAkAgAA2/PzI0r8O5JEAAAAGEgSAQCA7TEn0USTCAAAbI8lcEwMNwMAAMBAkggAAGyPINFEkggAAAADSSIAALA95iSaSBIBAABgIEkEAAC2R5JoIkkEAACAgSQRAADYHkGiiSYRAADYHsPNJoabAQAAYCBJBAAAtkeQaCJJBAAAgIEkEQAA2B5zEk0kiQAAADCQJAIAANsjSDSRJAIAAMBAkggAAGyPOYkmkkQAAAAYSBIBAIDtESSaaBIBAIDtMdxsYrgZAAAABpJEAABgewSJprOySRzdpa6vSwAMlVsP9nUJgJv1i572dQmAm6ToIF+XgL84K5tEAACA8mBOook5iQAAADCQJAIAANsjSDSRJAIAAMBAkggAAGyPOYkmmkQAAGB79IgmhpsBAABgIEkEAAC2x3CziSQRAAAABpJEAABgeySJJpJEAAAAGEgSAQCA7REkmkgSAQAAYCBJBAAAtsecRBNNIgAAsD16RBPDzQAAADCQJAIAANtjuNlEkggAAAADSSIAALA9gkQTSSIAAAAMJIkAAMD2/IgSDSSJAAAAMJAkAgAA2yNINNEkAgAA22MJHBPDzQAAADCQJAIAANvzI0g0kCQCAADAQJIIAABsjzmJJpJEAACACuT333/XDTfcoCpVqig4OFhNmjTR119/7dpvWZYeeeQRxcfHKzg4WCkpKdq8ebPH66BJBAAAtudweO9VHn/88YfatWungIAAffrpp1q/fr2eeeYZVa5c2XXM+PHjNXHiRGVmZmrlypUKCQlR165ddejQIY/eE4abAQAAKognn3xS1apV08yZM13bkpKSXP9sWZYmTJighx9+WD179pQkvfrqq4qNjdX8+fPVr18/j9VCkggAAGzP4cX/FRUVqaCgwO1VVFRUah0ffPCBWrVqpauvvloxMTFq0aKFXnzxRdf+rVu3KicnRykpKa5tERERatOmjbKysjx6T2gSAQCA7fk5vPfKyMhQRESE2ysjI6PUOn7++WdNmzZNderU0cKFC3XnnXfq7rvv1qxZsyRJOTk5kqTY2Fi398XGxrr2eQrDzQAAAF40YsQIpaenu21zOp2lHltSUqJWrVpp3LhxkqQWLVro+++/V2ZmptLS0rxe61+RJAIAANtzOBxeezmdToWHh7u9TtQkxsfHq2HDhm7bGjRooO3bt0uS4uLiJEm5ublux+Tm5rr2eQpNIgAAQAXRrl07bdy40W3bpk2bVKNGDUnHHmKJi4vT4sWLXfsLCgq0cuVKJScne7QWhpsBAIDtVZS1tIcNG6a2bdtq3Lhx6tu3r1atWqUXXnhBL7zwgqRjiefQoUP12GOPqU6dOkpKStLIkSOVkJCg1NRUj9ZCkwgAAFBBtG7dWvPmzdOIESM0duxYJSUlacKECbr++utdx9x///0qLCzUbbfdpvz8fF100UVasGCBgoKCPFqLw7Isy6NnrAAOHDnrPhLOAlUuGOLrEgA36xc97esSADdJ0Z5tcsqj94xsr537vYEtvXZub2JOIgAAAAwMNwMAANurKHMSKxKaRAAAYHsOukQDw80AAAAwkCQCAADbI0g0kSQCAADAQJIIAABsz48o0UCSCAAAAANJIgAAsD1yRBNJIgAAAAwkiQAAwPZYJ9FEkwgAAGzPjx7RwHAzAAAADCSJAADA9hhuNpEkAgAAwECSCAAAbI8g0USSCAAAAANJIgAAsD3mJJrK1CR+8MEHZT7hlVdeedLFAAAAoGIoU5OYmppappM5HA4VFxefSj0AAACnHeskmsrUJJaUlHi7DgAAAJ9huNnEgysAAAAwnNSDK4WFhVq2bJm2b9+uw4cPu+27++67PVIYAADA6UKOaCp3k7hmzRpdfvnlOnDggAoLCxUVFaXdu3erUqVKiomJoUkEAAA4C5R7uHnYsGHq0aOH/vjjDwUHB+urr77Stm3b1LJlSz399NPeqBEAAMCr/BwOr73OVOVuEteuXavhw4fLz89P/v7+KioqUrVq1TR+/Hg99NBD3qgRAAAAp1m5m8SAgAD5+R17W0xMjLZv3y5JioiI0K+//urZ6gAAAE4Dh8N7rzNVuecktmjRQqtXr1adOnXUsWNHPfLII9q9e7dee+01NW7c2Bs1AgAA4DQrd5I4btw4xcfHS5Ief/xxVa5cWXfeeafy8vL0wgsveLxAAAAAb3M4HF57nanKnSS2atXK9c8xMTFasGCBRwsCAACA753UOokAAABnkzM48POacjeJSUlJ/xid/vzzz6dUEHwv++vVenXmDK1f/4N25+Xp2ecnq/MlKb4uC2exdufX0rCbUnR+w+qKrxqhvsNe0IdLv3U7ZuSd3TWgV1tFhgUra93PunvcXP20Pc+1//6BXdWtfSM1rXueDh89qvgO95/uj4Gz2Hdrs/XOnFe0+ccN2rsnT49kPKe2HS527X9txjQt+3yB8nblKCAgQLXrNVT/2warfqOmPqwa5XEmL1XjLeVuEocOHer285EjR7RmzRotWLBA9913n6fqgg8dPHhQdevVV89efTR86BBflwMbCAl26rtNv+vV97M099nbjP3D+6forms76tZHXtMvv+/RI3ddoQ+nDFKLPo+p6PBRSVJggL/eW7RGK7/dqrTU5NP9EXCWO3TwoJJq11OX7ql69KF0Y/951WrorvQRik84T0VFhzRv7ut6aNidennuh4qsHOWDioFTV+4m8Z577il1+5QpU/T111+fckHwvYvad9BF7Tv4ugzYyGdfrNdnX6w/4f5B13XWky8u1EdLv5Mk3TLyVW37PENXdm6mtxdmS5Iey/xEknRDjzbeLxi20zr5IrVOvuiE+zt3udzt59vuvlcLP5qnrT9tVotW/E6eCQgSTeV+uvlEunXrpnfffddTpwMASVLiuVUUXzVCS1b+6NpWsP+QVn//i9o0TfRdYcAJHDlyRJ++/65CQsNUs3ZdX5cDnDSPPbjyzjvvKCqKSB2AZ8VFh0uSdu390237rj1/KrZKuC9KAkq18otlyhj1gIoOHVJUlWiNm5CpiMjKvi4LZXQmL1XjLSe1mPZfb6RlWcrJyVFeXp6mTp3q0eJ+/fVXjRo1Si+//PIJjykqKlJRUZHbtmK/QDmdTo/WAgDAP2l2fmtNfeUt7cvP16cfvqtxI+/T8y++rsjKVXxdGnBSyt0k9uzZ061J9PPzU9WqVdWpUyfVr1/fo8Xt3btXs2bN+scmMSMjQ2PGjHHb9tDDj+g/j4z2aC0AfCNnd4EkKSYqzPXPkhRTJUzfbvzNV2UBhqDgSko4r7oSzquuBo2b6uZremjBh/PV76aBvi4NZeCx+XdnkXI3iaNHj/bYxT/44IN/3F+W5XRGjBih9HT3J82K/QJPqS4AFccvv+/Rzrx96tymnr7d9LskKSwkSK0bJ+rFt1f4uDrgxKySEh05ctjXZQAnrdxNor+/v3bu3KmYmBi37Xv27FFMTIyKi4vLfK7U1FQ5HA5ZlnXCY/5tjoDT6TSGlg8cOfH58O8OHCjUr9u3u37+/ffftPHHDQqPiFB8fIIPK8PZKiQ4ULWqVXX9nHhuFTWte67+KDigX3P+0JQ5/9UDt1ymLdvz9MvvezTqru7ambdPH/x3nes91eIqq3J4JVWLryx/Pz81rXuuJOmnX/NUeJD/UOPUHDxwQDt++78/F3N2/K6fNv2osPAIhUdE6I1ZL+nCizopKjpaBfn5+vC9N7V79y6173ypD6tGeTAn0VTuJvFEDV1RUZECA8uX4MXHx2vq1Knq2bNnqfvXrl2rli1blrdEnKL133+vW29Oc/38zPgnJEk9eqZq7ONP+KosnMXOb1hDn730f8trjb+3jyTptQ++0m2jXtczr3yuSsFOTX74WkWGBevLtT/pykFTXWskSscW277xygtdP6+cO0KS1OWW5/W/7M2n6ZPgbLXpxx/0wJBbXD+/MOlpSVJKtyt1930P69dtW/X5px+oYF++wsIjVbdBIz09daYSa9b2VckoJz96RIPD+qcY7y8mTpwoSRo2bJgeffRRhYaGuvYVFxdr+fLl+uWXX7RmzZoyX/zKK69U8+bNNXbs2FL3r1u3Ti1atFBJSUmZzymRJKJiqnIBC5OjYlm/6GlflwC4SYoO8tm1h77/478fdJIm9PTsMxunS5mTxOeee07SsSQxMzNT/v7+rn2BgYFKTExUZmZmuS5+3333qbCw8IT7a9eurf/+97/lOicAAEB5kSSaytwkbt26VZLUuXNnvffee6pc+dTXfmrfvv0/7g8JCVHHjh1P+ToAAAAon3LPSSTZAwAAZxseXDGVe1mgPn366MknnzS2jx8/XldffbVHigIAAIBvlbtJXL58uS6//HJje7du3bR8+XKPFAUAAHA6+Tm89zpTlbtJ3L9/f6lL3QQEBKigoKCUdwAAAOBMU+4msUmTJpo7d66x/c0331TDhg09UhQAAMDp5HB473WmKveDKyNHjlTv3r31008/6eKLL5YkLV68WHPmzNE777zj8QIBAAC8ze9M7ua8pNxNYo8ePTR//nyNGzdO77zzjoKDg9WsWTMtWbJEUVFR3qgRAAAAp1m5m0RJ6t69u7p37y5JKigo0BtvvKF7771X2dnZ5fruZgAAgIqg3PPvbOCk78ny5cuVlpamhIQEPfPMM7r44ov11VdfebI2AAAA+Ei5ksScnBy98sormjFjhgoKCtS3b18VFRVp/vz5PLQCAADOWExJNJU5SezRo4fq1aunb7/9VhMmTNCOHTs0adIkb9YGAAAAHylzkvjpp5/q7rvv1p133qk6dep4syYAAIDTiqebTWVOElesWKE///xTLVu2VJs2bTR58mTt3r3bm7UBAADAR8rcJF544YV68cUXtXPnTt1+++168803lZCQoJKSEi1atEh//vmnN+sEAADwGhbTNpX76eaQkBDdfPPNWrFihb777jsNHz5cTzzxhGJiYnTllVd6o0YAAACv4rubTae0LFC9evU0fvx4/fbbb3rjjTc8VRMAAAB87KQW0/47f39/paamKjU11ROnAwAAOK14cMXEAuMAAAAweCRJBAAAOJMRJJpIEgEAAGAgSQQAALZ3Jj+F7C0kiQAAADCQJAIAANtziCjx72gSAQCA7THcbGK4GQAAAAaSRAAAYHskiSaSRAAAABhIEgEAgO05WE3bQJIIAAAAA0kiAACwPeYkmkgSAQAAYCBJBAAAtseURBNNIgAAsD0/ukQDw80AAAAwkCQCAADb48EVE0kiAAAADCSJAADA9piSaCJJBAAAqKCeeOIJORwODR061LXt0KFDGjRokKpUqaLQ0FD16dNHubm5Hr82TSIAALA9Pzm89jpZq1ev1vTp09W0aVO37cOGDdOHH36ot99+W8uWLdOOHTvUu3fvU70FBppEAACACmb//v26/vrr9eKLL6py5cqu7fv27dOMGTP07LPP6uKLL1bLli01c+ZMffnll/rqq688WgNNIgAAsD2Hw3uvoqIiFRQUuL2Kior+sZ5Bgwape/fuSklJcduenZ2tI0eOuG2vX7++qlevrqysLI/eE5pEAABge34O770yMjIUERHh9srIyDhhLW+++aa++eabUo/JyclRYGCgIiMj3bbHxsYqJyfHo/eEp5sBAAC8aMSIEUpPT3fb5nQ6Sz32119/1T333KNFixYpKCjodJR3QjSJAADA9rz5tXxOp/OETeHfZWdna9euXTr//PNd24qLi7V8+XJNnjxZCxcu1OHDh5Wfn++WJubm5iouLs6jddMkAgAAVBCXXHKJvvvuO7dtAwYMUP369fXAAw+oWrVqCggI0OLFi9WnTx9J0saNG7V9+3YlJyd7tBaaRAAAYHsVZTHtsLAwNW7c2G1bSEiIqlSp4to+cOBApaenKyoqSuHh4RoyZIiSk5N14YUXerQWmkQAAIAzyHPPPSc/Pz/16dNHRUVF6tq1q6ZOnerx6zgsy7I8flYfO3DkrPtIOAtUuWCIr0sA3Kxf9LSvSwDcJEX77kGNGau2e+3cAy+o7rVzexNL4AAAAMDAcDMAALC9ijInsSKhSQQAALbH0KqJewIAAAADSSIAALA9B+PNBpJEAAAAGEgSAQCA7ZEjmkgSAQAAYCBJBAAAtufHnEQDSSIAAAAMJIkAAMD2yBFNNIkAAMD2GG02MdwMAAAAA0kiAACwPRbTNpEkAgAAwECSCAAAbI/UzMQ9AQAAgIEkEQAA2B5zEk0kiQAAADCQJAIAANsjRzSRJAIAAMBAkggAAGyPOYmms7JJ9ONfNCqgHV887+sSADe9Xljp6xIAN0uHtvXZtRlaNXFPAAAAYDgrk0QAAIDyYLjZRJIIAAAAA0kiAACwPXJEE0kiAAAADCSJAADA9piSaCJJBAAAgIEkEQAA2J4fsxINNIkAAMD2GG42MdwMAAAAA0kiAACwPQfDzQaSRAAAABhIEgEAgO0xJ9FEkggAAAADSSIAALA9lsAxkSQCAADAQJIIAABsjzmJJppEAABgezSJJoabAQAAYCBJBAAAtsdi2iaSRAAAABhIEgEAgO35ESQaSBIBAABgIEkEAAC2x5xEE0kiAAAADCSJAADA9lgn0USTCAAAbI/hZhPDzQAAADCQJAIAANtjCRwTSSIAAAAMJIkAAMD2mJNoIkkEAACAgSQRAADYHkvgmEgSAQAAYCBJBAAAtkeQaKJJBAAAtufHeLOB4WYAAAAYSBIBAIDtkSOaSBIBAABgIEkEAAAgSjSQJAIAAMBAkggAAGyPr+UzkSQCAADAQJIIAABsj2USTTSJAADA9ugRTQw3AwAAwECSCAAAQJRoIEkEAACAgSQRAADYHkvgmEgSAQAAYCBJBAAAtscSOCaSRAAAABhIEgEAgO0RJJpoEgEAAOgSDQw3AwAAwECSCAAAbI8lcEwkiQAAADDQJAIAANtzOLz3Ko+MjAy1bt1aYWFhiomJUWpqqjZu3Oh2zKFDhzRo0CBVqVJFoaGh6tOnj3Jzcz14N46hSQQAAKggli1bpkGDBumrr77SokWLdOTIEXXp0kWFhYWuY4YNG6YPP/xQb7/9tpYtW6YdO3aod+/eHq/FYVmW5fGz+tiho76uADAdPFzs6xIAN71eWOnrEgA3S4e29dm1123/02vnblY97KTfm5eXp5iYGC1btkwdOnTQvn37VLVqVc2ZM0dXXXWVJOnHH39UgwYNlJWVpQsvvNBTZZMkAgAAeFNRUZEKCgrcXkVFRWV67759+yRJUVFRkqTs7GwdOXJEKSkprmPq16+v6tWrKysry6N10yQCAAA4vPfKyMhQRESE2ysjI+NfSyopKdHQoUPVrl07NW7cWJKUk5OjwMBARUZGuh0bGxurnJycU7sHf8MSOAAAwPa8uQTOiBEjlJ6e7rbN6XT+6/sGDRqk77//XitWrPBWaf+IJhEAAMCLnE5nmZrCvxo8eLA++ugjLV++XOedd55re1xcnA4fPqz8/Hy3NDE3N1dxcXGeKlkSw80AAAAVZgkcy7I0ePBgzZs3T0uWLFFSUpLb/pYtWyogIECLFy92bdu4caO2b9+u5ORkT9wKF5JEAACACmLQoEGaM2eO3n//fYWFhbnmGUZERCg4OFgREREaOHCg0tPTFRUVpfDwcA0ZMkTJyckefbJZokkEAACoMF/KN23aNElSp06d3LbPnDlT/fv3lyQ999xz8vPzU58+fVRUVKSuXbtq6tSpHq+FJhEAAKCCKMvy1UFBQZoyZYqmTJni1VpoEgEAACpKlFiB8OAKAAAADCSJKNWbc2Zr1swZ2r07T3Xr1deDD41Uk6ZNfV0WbOrFzMmaMd19vk2NxCTNnfexjyqCHUWHBOr2i2rogsRIBQX46ff8Q3rysy3auKvQODb94pq6smmcJi/bqnfW7PRBtSgvb66TeKaiSYRhwaef6OnxGXp41Bg1adJMs1+bpTtvH6j3P1qgKlWq+Lo82FTNWrU1KXOG62d/f/74wukT6vTX5Gsaa82vBXpg/gblHzyi8yKD9GfRUePYi2pFqWF8mPL2l+1r14CKiuFmGF6bNVO9r+qr1F59VKt2bT08aoyCgoI0/713fV0abMzf319Voqu6XpGVK/u6JNjIda3O1a4/D+vJRVv0Y+5+5RQU6evt+7Rjn3sjGB0SqHs6JemxTzepuOTfH0BAxVFR1kmsSPirONwcOXxYG9b/oIG33u7a5ufnpwsvbKtv163xYWWwu1+3b9cVl3ZUoNOpxk2b6a4hwxQXn+DrsmATbWtGafW2fI2+vK6anReh3fuLNP/bHH38/S7XMQ5JD11WR29m79Avew/6rliclDO4l/MamkS4+SP/DxUXFxvDylWqVNHWrT/7qCrYXaPGTTVy7OOqXiNJe3bnacb0qbrj5hs1+50PFBIS4uvyYAMJEUHq2TROb32zQ6+v/l31Y0N1d6ckHS22tHBDniTp2tbnqrjE0rtrmYOIs4PPm8SDBw8qOztbUVFRatiwodu+Q4cO6a233tJNN910wvcXFRWpqMg97rf8y/8diQAqrrYXdXD9c5269dSoSVOlXp6ixZ8t0JW9+viwMtiFwyFtzN2vl77cLknakleopCqVdGXTOC3ckKe6MSG6qnm8bp2zzseV4qQRJRp8Oidx06ZNatCggTp06KAmTZqoY8eO2rnz//4Gtm/fPg0YMOAfz5GRkaGIiAi311NPZni79LNW5cjK8vf31549e9y279mzR9HR0T6qCnAXFhau6tUT9duv23xdCmxiT+ERbfvbEPK2Pw4oJixQktT03HBFVgrQWwNbafHdyVp8d7LiwoN0Z/tEvXnz+b4oGThlPk0SH3jgATVu3Fhff/218vPzNXToULVr105Lly5V9erVy3SOESNGKD093W2b5U+KeLICAgPVoGEjrfwqSxdfkiJJKikp0cqVWep37Q0+rg445sCBQv3+23Zd1r2Hr0uBTXy/o0DVKge7basWGazcgmMjWZ9tyFP29n1u+8f3aqBFG/L06fpdQsXHEjgmnzaJX375pT7//HNFR0crOjpaH374oe666y61b99e//3vf8s018jpNIeWD5krEqAcbkwboJEPPaBGjRqrcZOmev21WTp48KBSe/X2dWmwqYnPjtdFHTorLiFBu3ft0ouZk+Xn568ul3X3dWmwibfX7NSUvo11fetztXTTHtWPC9UVTWL1zOc/SZIKDh1Vwd/+41NcYmnvgSP69Y9DvigZOGU+bRIPHjyoc875vxIcDoemTZumwYMHq2PHjpozZ44Pq7Ovy7pdrj/27tXUyRO1e3ee6tVvoKnTX1IVhpvhI7tyc/XIiHu1b1++IitHqVnz8/XSq2+oclSUr0uDTWzM3a+RH23Ure2qK61NNe0sOKTJy7bq8427fV0aPORMXqrGWxxWWb5J2ksuuOACDRkyRDfeeKOxb/DgwZo9e7YKCgpUXFxcrvOSJKIiOni4fL/HgLf1emGlr0sA3Cwd2tZn196Yc8Br564XV8lr5/Ymnz640qtXL73xxhul7ps8ebKuvfZa+bCHBQAANuHw4utM5dMk0VtIElERkSSioiFJREXjyyRxU673ksS6sSSJAAAAOEv4fDFtAAAAX2MJHBNJIgAAAAwkiQAAwPZYAsdEkggAAAADSSIAALA9gkQTSSIAAAAMJIkAAABEiQaaRAAAYHssgWNiuBkAAAAGkkQAAGB7LIFjIkkEAACAgSQRAADYHkGiiSQRAAAABpJEAAAAokQDSSIAAAAMJIkAAMD2WCfRRJMIAABsjyVwTAw3AwAAwECSCAAAbI8g0USSCAAAAANJIgAAsD3mJJpIEgEAAGAgSQQAAGBWooEkEQAAAAaSRAAAYHvMSTTRJAIAANujRzQx3AwAAAADSSIAALA9hptNJIkAAAAwkCQCAADbczAr0UCSCAAAAANJIgAAAEGigSQRAAAABpJEAABgewSJJppEAABgeyyBY2K4GQAAAAaSRAAAYHssgWMiSQQAAICBJBEAAIAg0UCSCAAAAANJIgAAsD2CRBNJIgAAAAwkiQAAwPZYJ9FEkwgAAGyPJXBMDDcDAADAQJIIAABsj+FmE0kiAAAADDSJAAAAMNAkAgAAwMCcRAAAYHvMSTSRJAIAAMBAkggAAGyPdRJNNIkAAMD2GG42MdwMAAAAA0kiAACwPYJEE0kiAAAADCSJAAAARIkGkkQAAAAYSBIBAIDtsQSOiSQRAAAABpJEAABge6yTaCJJBAAAgIEkEQAA2B5BookmEQAAgC7RwHAzAAAADDSJAADA9hxe/N/JmDJlihITExUUFKQ2bdpo1apVHv7E/44mEQAAoAKZO3eu0tPTNWrUKH3zzTdq1qyZunbtql27dp3WOmgSAQCA7Tkc3nuV17PPPqtbb71VAwYMUMOGDZWZmalKlSrp5Zdf9vwH/wc0iQAAAF5UVFSkgoICt1dRUVGpxx4+fFjZ2dlKSUlxbfPz81NKSoqysrJOV8mSztKnm4POyk91+hUVFSkjI0MjRoyQ0+n0dTlnvKBz/H1dwhmP30nPWjq0ra9LOCvwe3l28GbvMPqxDI0ZM8Zt26hRozR69Gjj2N27d6u4uFixsbFu22NjY/Xjjz96r8hSOCzLsk7rFXHGKCgoUEREhPbt26fw8HBflwPwO4kKid9L/JuioiIjOXQ6naX+pWLHjh0699xz9eWXXyo5Odm1/f7779eyZcu0cuVKr9d7HJkbAACAF52oISxNdHS0/P39lZub67Y9NzdXcXFx3ijvhJiTCAAAUEEEBgaqZcuWWrx4sWtbSUmJFi9e7JYsng4kiQAAABVIenq60tLS1KpVK11wwQWaMGGCCgsLNWDAgNNaB00iTsjpdGrUqFFMxEaFwe8kKiJ+L+Fp11xzjfLy8vTII48oJydHzZs314IFC4yHWbyNB1cAAABgYE4iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIko1ZcoUJSYmKigoSG3atNGqVat8XRJsbPny5erRo4cSEhLkcDg0f/58X5cEm8vIyFDr1q0VFhammJgYpaamauPGjb4uC/AomkQY5s6dq/T0dI0aNUrffPONmjVrpq5du2rXrl2+Lg02VVhYqGbNmmnKlCm+LgWQJC1btkyDBg3SV199pUWLFunIkSPq0qWLCgsLfV0a4DEsgQNDmzZt1Lp1a02ePFnSsZXeq1WrpiFDhujBBx/0cXWwO4fDoXnz5ik1NdXXpQAueXl5iomJ0bJly9ShQwdflwN4BEki3Bw+fFjZ2dlKSUlxbfPz81NKSoqysrJ8WBkAVFz79u2TJEVFRfm4EsBzaBLhZvfu3SouLjZWdY+NjVVOTo6PqgKAiqukpERDhw5Vu3bt1LhxY1+XA3gMX8sHAMApGDRokL7//nutWLHC16UAHkWTCDfR0dHy9/dXbm6u2/bc3FzFxcX5qCoAqJgGDx6sjz76SMuXL9d5553n63IAj2K4GW4CAwPVsmVLLV682LWtpKREixcvVnJysg8rA4CKw7IsDR48WPPmzdOSJUuUlJTk65IAjyNJhCE9PV1paWlq1aqVLrjgAk2YMEGFhYUaMGCAr0uDTe3fv19btmxx/bx161atXbtWUVFRql69ug8rg10NGjRIc+bM0fvvv6+wsDDXnO2IiAgFBwf7uDrAM1gCB6WaPHmynnrqKeXk5Kh58+aaOHGi2rRp4+uyYFNLly5V586dje1paWl65ZVXTn9BsD2Hw1Hq9pkzZ6p///6ntxjAS2gSAQAAYGBOIgAAAAw0iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00igAqrf//+Sk1Ndf3cqVMnDR069LTXsXTpUjkcDuXn55/2awOAr9AkAii3/v37y+FwyOFwKDAwULVr19bYsWN19OhRr173vffe06OPPlqmY2nsAODUnOPrAgCcmS677DLNnDlTRUVF+uSTTzRo0CAFBARoxIgRbscdPnxYgYGBHrlmVFSUR84DAPh3JIkATorT6VRcXJxq1KihO++8UykpKfrggw9cQ8SPP/64EhISVK9ePUnSr7/+qr59+yoyMlJRUVHq2bOnfvnlF9f5iouLlZ6ersjISFWpUkX333+//v7V8n8fbi4qKtIDDzygatWqyel0qnbt2poxY4Z++eUXde7cWZJUuXJlORwO9e/fX5JUUlKijIwMJSUlKTg4WM2aNdM777zjdp1PPvlEdevWVXBwsDp37uxWJwDYBU0iAI8IDg7W4cOHJUmLFy/Wxo0btWjRIn300Uc6cuSIunbtqrCwMP3vf//TF198odDQUF122WWu9zzzzDN65ZVX9PLLL2vFihXau3ev5s2b94/XvOmmm/TGG29o4sSJ2rBhg6ZPn67Q0FBVq1ZN7777riRp48aN2rlzp55//nlJUkZGhl599VVlZmbqhx9+0LBhw3TDDTdo2bJlko41s71791aPHj20du1a3XLLLXrwwQe9ddsAoMJiuBnAKbEsS4sXL9bChQs1ZMgQ5eXlKSQkRC+99JJrmPn1119XSUmJXnrpJTkcDknSzJkzFRkZqaVLl6pLly6aMGGCRowYod69e0uSMjMztXDhwhNed9OmTXrrrbe0aNEipaSkSJJq1qzp2n98aDomJkaRkZGSjiWP48aN0+eff67k5GTXe1asWKHp06erY8eOmjZtmmrVqqVnnnlGklSvXj199913evLJJz141wCg4qNJBHBSPvroI4WGhurIkSMqKSnRddddp9GjR2vQoEFq0qSJ2zzEdevWacuWLQoLC3M7x6FDh/TTTz9p37592rlzp9q0aePad84556hVq1bGkPNxa9eulb+/vzp27Fjmmrds2aIDBw7o0ksvddt++PBhtWjRQpK0YcMGtzokuRpKALATmkQAJ6Vz586aNm2aAgMDlZCQoHPO+b8/TkJCQtyO3b9/v1q2bKnZs2cb56latepJXT84OLjc79m/f78k6eOPP9a5557rts/pdJ5UHQBwtqJJBHBSQkJCVLt27TIde/7552vu3LmKiYlReHh4qcfEx8dr5cqV6tChgyTp6NGjys7O1vnnn1/q8U2aNFFJSYmWLVvmGm7+q+NJZnFxsWtbw4YN5XQ6tX379hMmkA0aNNAHH3zgtu2rr7769w8JAGcZHlwB4HXXX3+9oqOj1bNnT/3vf//T1q1btXTpUt1999367bffJEn33HOPnnjiCc2fP18//vij7rrrrn9c4zAxMVFpaWm6+eabNX/+fNc533rrLUlSjRo15HA49NFHHykvL0/79+9XWFiY7r33Xg0bNkyzZs3STz/9pG+++UaTJk3SrFmzJEl33HGHNm/erPvuu08bN27UnDlz9Morr3j7FgFAhUOTCMDrKlWqpOXLl6t69erq3bu3GjRooIEDB+rQoUOuZHH48OG68cYblZaWpuTkZIWFhalXr17/eN5p06bpqquu0l133aX69evr1ltvVWFhoSTp3HPP1ZgxY/Tggw8qNjZWgwcPliQ9+uijGjlypDIyMtSgQQNddtll+vjjj5WUlCRJql69ut59913Nnz9fzZo1U2ZmpsaNG+fFuwMAFZPDOtGscAAAANgWSSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQAAADDQJAIAAMDw/wBPBw8noUQrZQAAAABJRU5ErkJggg==\n"},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.98      0.98      0.98        49\n           1       0.95      0.88      0.91       115\n           2       0.82      0.93      0.87        69\n\n    accuracy                           0.91       233\n   macro avg       0.92      0.93      0.92       233\nweighted avg       0.92      0.91      0.91       233\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"'''import os\n\nfile_path = \"/kaggle/working/nail_disease_model_weights.h5\"\n\nif os.path.exists(file_path):\n    os.remove(file_path)\n    print(\"File deleted successfully.\")\nelse:\n    print(\"File not found.\")\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:16:17.154656Z","iopub.execute_input":"2025-10-21T00:16:17.154872Z","iopub.status.idle":"2025-10-21T00:16:17.159422Z","shell.execute_reply.started":"2025-10-21T00:16:17.154855Z","shell.execute_reply":"2025-10-21T00:16:17.158903Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'import os\\n\\nfile_path = \"/kaggle/working/nail_disease_model_weights.h5\"\\n\\nif os.path.exists(file_path):\\n    os.remove(file_path)\\n    print(\"File deleted successfully.\")\\nelse:\\n    print(\"File not found.\")\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}